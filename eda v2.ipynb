{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d013ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "664654a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdce0f06",
   "metadata": {},
   "source": [
    "## **Carga de datos (Fase 0)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72db2e",
   "metadata": {},
   "source": [
    "#### Datos 2023-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4563e246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resumen de hojas y columnas ---\n",
      "                         hoja  filas  columnas  \\\n",
      "0             Consolidado KPI  12010       125   \n",
      "1                       Metas     48        57   \n",
      "2      Consolidado Produccion  12011        19   \n",
      "3    Totalizadores Produccion  12009        41   \n",
      "4              Consolidado EE  12011        24   \n",
      "5       Totalizadores Energia  12009        54   \n",
      "6            Consolidado Agua  12011        24   \n",
      "7          Totalizadores Agua  12009        44   \n",
      "8        Consolidado GasVapor  12011        20   \n",
      "9   Totalizadores Gas y Vapor  12009        24   \n",
      "10           Consolidado Aire  12011        14   \n",
      "11         Totalizadores Aire  12009        12   \n",
      "12          Totalizadores CO2  12009         9   \n",
      "13    Totalizadores Efluentes  12009         9   \n",
      "14       Totalizadores Glicol  12009         8   \n",
      "15            Seguimiento Dia  12009         4   \n",
      "16                   Auxiliar  12011        38   \n",
      "17          Kw Frio  Hl Mosto  12372        15   \n",
      "\n",
      "                                     nombres_columnas  \n",
      "0   DIA, HORA, EE Planta / Hl, EE Elaboracion / Hl...  \n",
      "1   Mes / Año, Año + Mes, Agua Planta, EE Planta, ...  \n",
      "2   DIA, HORA, Hl de Mosto, Hl Cerveza Cocina, Hl ...  \n",
      "3   DIA, HORA, HL Mosto Budweiser, HL Mosto Tecate...  \n",
      "4   DIA, HORA, Planta (Kw), Elaboracion (Kw), Bode...  \n",
      "5   DIA, HORA, KW Gral Planta, KW Trafo 4, KW Traf...  \n",
      "6   DIA, HORA, Agua Planta (Hl), Agua Elaboracion ...  \n",
      "7   DIA, HORA, Red L1 y L2, FC L1 y L2, Red Paste ...  \n",
      "8   DIA, HORA, Conversion Kg/Mj, Gas Planta (Mj), ...  \n",
      "9   DIA, HORA, M3_Tot_Gas, Tot_Vapor_Caldera 3, To...  \n",
      "10  DIA, HORA, Aire Producido (M3), Aire Planta (M...  \n",
      "11  DIA, HORA, Totalizador_Aire_L2, Totalizador_Ai...  \n",
      "12  DIA, HORA, Totalizador_L2_Barriles, Totalizado...  \n",
      "13  DIA, HORA, Totalizador Bba P1, Totalizador Bba...  \n",
      "14  DIA, HORA, Tot L3, L4 y Planta de CO2, Tot A40...  \n",
      "15                 DIA, HORA, Ultimo Dato del Dia, Id  \n",
      "16  Unnamed: 0, DIA, HORA, Unnamed: 3, DIA.1, HORA...  \n",
      "17  Dia, Hora, Dia / Hora, Unnamed: 3, Hl de Mosto...  \n"
     ]
    }
   ],
   "source": [
    "# 1) Cargar el archivo una sola vez\n",
    "xls = pd.ExcelFile('data/Totalizadores Planta de Cerveza 2023_2024.xlsx')\n",
    "\n",
    "# 2) Crear un dict con un DataFrame por hoja\n",
    "dfs_2023_2024 = {}\n",
    "resumen = []\n",
    "\n",
    "for hoja in xls.sheet_names:\n",
    "    df = pd.read_excel(xls, sheet_name=hoja)\n",
    "    dfs_2023_2024[hoja] = df\n",
    "    resumen.append({\n",
    "        \"hoja\": hoja,\n",
    "        \"filas\": len(df),\n",
    "        \"columnas\": df.shape[1],\n",
    "        \"nombres_columnas\": \", \".join(map(str, df.columns.tolist()))\n",
    "    })\n",
    "\n",
    "# 3) Mostrar un resumen amigable\n",
    "resumen_df = pd.DataFrame(resumen)\n",
    "\n",
    "print(\"--- Resumen de hojas y columnas ---\")\n",
    "print(resumen_df)\n",
    "\n",
    "# Nota: Los DataFrames quedan disponibles en el dict dfs (ej: dfs[\"NombreDeLaHoja\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75e41c6",
   "metadata": {},
   "source": [
    "### **Los dias faltantes son:**\n",
    "- 31-3-2023\n",
    "- 31-5-2023\n",
    "- 31-10-2023\n",
    "- desde 31-12-2023 hasta 30-6-24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab38d8",
   "metadata": {},
   "source": [
    "### **Creacion del Diccionario**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e896ffe4",
   "metadata": {},
   "source": [
    "Una vez cargada toda la hoja de datos del 2023/2024 en un diccionario, visto los días faltantes y los días en los que no se cargó la última hora (23:59), vamos a crear un diccionario con todos los df con las filas que tengan la última hora de cada día ordenado por orden cronológico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fea5708",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "\n",
    "def _to_date(x):\n",
    "    try:\n",
    "        return pd.to_datetime(x, errors=\"coerce\").date()\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def _to_minutes(x):\n",
    "    if pd.isna(x):\n",
    "        return -1\n",
    "    ts = pd.to_datetime(x, errors=\"coerce\")\n",
    "    if pd.notna(ts):\n",
    "        return int(ts.hour) * 60 + int(ts.minute)\n",
    "    try:\n",
    "        h = int(float(str(x).replace(\",\", \".\")))\n",
    "        if 0 <= h <= 23:\n",
    "            return h * 60\n",
    "    except Exception:\n",
    "        pass\n",
    "    return -1\n",
    "\n",
    "dfs_23_24 = {}\n",
    "hojas_saltadas = []\n",
    "\n",
    "for hoja, df in dfs_2023_2024.items():\n",
    "    if DAY_COL not in df.columns or HOUR_COL not in df.columns:\n",
    "        hojas_saltadas.append((hoja, \"Falta DIA u HORA\"))\n",
    "        continue\n",
    "\n",
    "    tmp = df.copy()\n",
    "    tmp[\"_dia\"]  = tmp[DAY_COL].map(_to_date)\n",
    "    tmp[\"_mins\"] = tmp[HOUR_COL].map(_to_minutes)\n",
    "\n",
    "    # Filtramos filas sin día y agregamos orden determinístico\n",
    "    tmp = tmp.dropna(subset=[\"_dia\"]).copy()\n",
    "    if tmp.empty:\n",
    "        hojas_saltadas.append((hoja, \"Sin días válidos\"))\n",
    "        continue\n",
    "\n",
    "    tmp[\"_ord\"] = np.arange(len(tmp))  # <- evita usar el índice en sort_values\n",
    "\n",
    "    # Orden por día, hora (minutos) y orden original\n",
    "    tmp = tmp.sort_values([\"_dia\", \"_mins\", \"_ord\"], kind=\"stable\")\n",
    "\n",
    "    # Última fila por día (la mayor \"_mins\"; si empata, la última por \"_ord\")\n",
    "    ultimas = tmp.groupby(\"_dia\", as_index=False, sort=True).tail(1)\n",
    "\n",
    "    # Limpieza de columnas auxiliares y orden final\n",
    "    ultimas = ultimas.drop(columns=[\"_dia\", \"_mins\", \"_ord\"]).sort_values(DAY_COL).reset_index(drop=True)\n",
    "\n",
    "    dfs_23_24[hoja] = ultimas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4f08d",
   "metadata": {},
   "source": [
    "### **4 filas con última hora distinta de 23:59**\n",
    "- 2023-02-28 -> 23:00:00    \n",
    "- 2023-04-13 -> 19:00:00    \n",
    "- 2023-04-19 -> 16:00:00    \n",
    "- 2024-10-26 -> 07:00:00    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66394821",
   "metadata": {},
   "source": [
    "### **Interpolación**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f77ba0",
   "metadata": {},
   "source": [
    "Vamos a interpolar los 5 días faltantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ef53f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "\n",
    "def completar_e_interpolar_diario(df, day_col=DAY_COL, hour_col=HOUR_COL, hora_por_defecto=\"23:59:00\"):\n",
    "    g = df.copy()\n",
    "\n",
    "    # --- fecha como datetime (normalizada al día) ---\n",
    "    g[\"_fecha\"] = pd.to_datetime(g[day_col], errors=\"coerce\", dayfirst=True).dt.normalize()\n",
    "    g = g.dropna(subset=[\"_fecha\"]).sort_values(\"_fecha\").drop_duplicates(\"_fecha\", keep=\"last\")\n",
    "\n",
    "    # --- índice continuo día a día (agrega los días faltantes) ---\n",
    "    idx_full = pd.date_range(g[\"_fecha\"].min(), g[\"_fecha\"].max(), freq=\"D\")\n",
    "    g = g.set_index(\"_fecha\").reindex(idx_full)\n",
    "\n",
    "    # --- reconstruir columnas de fecha/hora ---\n",
    "    g[day_col] = g.index.date\n",
    "    if hour_col in g.columns:\n",
    "        g[hour_col] = g[hour_col].fillna(hora_por_defecto)\n",
    "    else:\n",
    "        g[hour_col] = hora_por_defecto\n",
    "\n",
    "    # --- interpolación SOLO en columnas numéricas ---\n",
    "    num_cols = g.select_dtypes(include=\"number\").columns\n",
    "    if len(num_cols):\n",
    "        # usa el índice temporal para interpolar; luego rellena bordes\n",
    "        g[num_cols] = g[num_cols].interpolate(method=\"time\").ffill().bfill()\n",
    "\n",
    "    return g.reset_index(drop=True)\n",
    "\n",
    "# Aplicarlo a TODO el diccionario (una hoja por vez)\n",
    "for nombre, df in dfs_23_24.items():\n",
    "    dfs_23_24[nombre] = completar_e_interpolar_diario(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad36346",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL = \"DIA\"\n",
    "inicio  = pd.Timestamp(\"2023-12-31\")\n",
    "fin     = pd.Timestamp(\"2024-06-30\")\n",
    "\n",
    "for nombre, df in dfs_23_24.items():\n",
    "    if DAY_COL not in df.columns or df.empty:\n",
    "        continue\n",
    "\n",
    "    # Normalizar a fecha y construir máscara para CONSERVAR lo que queda fuera del rango\n",
    "    fechas = pd.to_datetime(df[DAY_COL], dayfirst=True, errors=\"coerce\").dt.normalize()\n",
    "\n",
    "    # Rango INCLUSIVO: elimina 31/12/2023 ... 30/06/2024\n",
    "    mask_keep = (fechas < inicio) | (fechas > fin) | fechas.isna()\n",
    "\n",
    "    dfs_23_24[nombre] = df.loc[mask_keep].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492cb80d",
   "metadata": {},
   "source": [
    "#### Datos 2022-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df6bfb",
   "metadata": {},
   "source": [
    "Repetimos todo el proceso para los datos del 2022-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7dc1cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resumen de hojas y columnas ---\n",
      "                         hoja  filas  columnas  \\\n",
      "0             Consolidado KPI  15317       123   \n",
      "1                       Metas     36        57   \n",
      "2      Consolidado Produccion  15450        14   \n",
      "3    Totalizadores Produccion  15316        40   \n",
      "4              Consolidado EE  15450        24   \n",
      "5       Totalizadores Energia  15316        59   \n",
      "6            Consolidado Agua  15451        24   \n",
      "7          Totalizadores Agua  15316        43   \n",
      "8        Consolidado GasVapor  15460        20   \n",
      "9   Totalizadores Gas y Vapor  15316        23   \n",
      "10           Consolidado Aire  15649        14   \n",
      "11         Totalizadores Aire  15316        11   \n",
      "12          Totalizadores CO2  15317         8   \n",
      "13    Totalizadores Efluentes  15316         8   \n",
      "14       Totalizadores Glicol  15316         7   \n",
      "15            Seguimiento Dia  15316         5   \n",
      "16                   Auxiliar  15754        34   \n",
      "17          Kw Frio  Hl Mosto   6352        15   \n",
      "\n",
      "                                     nombres_columnas  \n",
      "0   DIA, HORA, EE Planta / Hl, EE Elaboracion / Hl...  \n",
      "1   Mes / Año, Año + Mes, Agua Planta, EE Planta, ...  \n",
      "2   DIA, HORA, Hl de Mosto, Hl Cerveza Cocina, Hl ...  \n",
      "3   DIA, HORA, HL Mosto Budweiser, HL Mosto Tecate...  \n",
      "4   DIA, HORA, Planta (Kw), Elaboracion (Kw), Bode...  \n",
      "5   DIA, HORA, KW Gral Planta, KW Trafo 4, KW Traf...  \n",
      "6   DIA, HORA, Agua Planta (Hl), Agua Elaboracion ...  \n",
      "7   DIA, HORA, Red L1 y L2, FC L1 y L2, Red Paste ...  \n",
      "8   DIA, HORA, Conversion Kg/Mj, Gas Planta (Mj), ...  \n",
      "9   DIA, HORA, M3_Tot_Gas, Tot_Vapor_Caldera 3, To...  \n",
      "10  DIA, HORA, Aire Producido (M3), Aire Planta (M...  \n",
      "11  DIA, HORA, Totalizador_Aire_L2, Totalizador_Ai...  \n",
      "12  DIA, HORA, Totalizador_L2_Barriles, Totalizado...  \n",
      "13  DIA, HORA, Totalizador Bba P1, Totalizador Bba...  \n",
      "14  DIA, HORA, Tot L3. L4 y Planta de CO2, Tot A40...  \n",
      "15  DIA, HORA, Ultimo Dato del Dia, Unnamed: 3, Un...  \n",
      "16  DIA, HORA,  ,  .1,  .2,  .3,  .4,  .5,  .6,  ....  \n",
      "17  Dia, Hora, Dia / Hora, Unnamed: 3, Hl de Mosto...  \n"
     ]
    }
   ],
   "source": [
    "# 1) Cargar el archivo una sola vez\n",
    "xls = pd.ExcelFile('data/Totalizadores Planta de Cerveza - 2022_2023.xlsx')\n",
    "\n",
    "# 2) Crear un dict con un DataFrame por hoja\n",
    "dfs_2022_2023 = {}\n",
    "resumen = []\n",
    "\n",
    "for hoja in xls.sheet_names:\n",
    "    df = pd.read_excel(xls, sheet_name=hoja)\n",
    "    dfs_2022_2023[hoja] = df\n",
    "    resumen.append({\n",
    "        \"hoja\": hoja,\n",
    "        \"filas\": len(df),\n",
    "        \"columnas\": df.shape[1],\n",
    "        \"nombres_columnas\": \", \".join(map(str, df.columns.tolist()))\n",
    "    })\n",
    "\n",
    "# 3) Mostrar un resumen amigable\n",
    "resumen_df = pd.DataFrame(resumen)\n",
    "\n",
    "print(\"--- Resumen de hojas y columnas ---\")\n",
    "print(resumen_df)\n",
    "\n",
    "# Nota: Los DataFrames quedan disponibles en el dict dfs (ej: dfs[\"NombreDeLaHoja\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901c1976",
   "metadata": {},
   "source": [
    "### **Los dias faltantes son:**\n",
    "- 31-3-2023\n",
    "- 31-5-2023\n",
    "- 31-10-2023\n",
    "- desde 07-03-2023 hasta 30-06-23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b307c5",
   "metadata": {},
   "source": [
    "### **Creacion del diccionario**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df854b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "\n",
    "dfs_22_23 = {}\n",
    "hojas_saltadas = []\n",
    "\n",
    "for hoja, df in dfs_2022_2023.items():\n",
    "    if DAY_COL not in df.columns or HOUR_COL not in df.columns:\n",
    "        hojas_saltadas.append((hoja, \"Falta DIA u HORA\"))\n",
    "        continue\n",
    "\n",
    "    tmp = df.copy()\n",
    "    tmp[\"_dia\"]  = tmp[DAY_COL].map(_to_date)\n",
    "    tmp[\"_mins\"] = tmp[HOUR_COL].map(_to_minutes)\n",
    "\n",
    "    # Filtramos filas sin día y agregamos orden determinístico\n",
    "    tmp = tmp.dropna(subset=[\"_dia\"]).copy()\n",
    "    if tmp.empty:\n",
    "        hojas_saltadas.append((hoja, \"Sin días válidos\"))\n",
    "        continue\n",
    "\n",
    "    tmp[\"_ord\"] = np.arange(len(tmp))  # <- evita usar el índice en sort_values\n",
    "\n",
    "    # Orden por día, hora (minutos) y orden original\n",
    "    tmp = tmp.sort_values([\"_dia\", \"_mins\", \"_ord\"], kind=\"stable\")\n",
    "\n",
    "    # Última fila por día (la mayor \"_mins\"; si empata, la última por \"_ord\")\n",
    "    ultimas = tmp.groupby(\"_dia\", as_index=False, sort=True).tail(1)\n",
    "\n",
    "    # Limpieza de columnas auxiliares y orden final\n",
    "    ultimas = ultimas.drop(columns=[\"_dia\", \"_mins\", \"_ord\"]).sort_values(DAY_COL).reset_index(drop=True)\n",
    "\n",
    "    dfs_22_23[hoja] = ultimas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230c2908",
   "metadata": {},
   "source": [
    "**4 filas con última hora distinta de 23:59**\n",
    "- 2022-03-02 -> 23:00:00    \n",
    "- 2022-07-13 -> 23:00:00    \n",
    "- 2023-02-28 -> 23:00:00    \n",
    "- 2023-03-06 -> 08:00:00    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea42918",
   "metadata": {},
   "source": [
    "### **Interpolación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c773668",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "\n",
    "# Aplicarlo a TODO el diccionario (una hoja por vez)\n",
    "for nombre, df in dfs_22_23.items():\n",
    "    dfs_22_23[nombre] = completar_e_interpolar_diario(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2399557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL = \"DIA\"\n",
    "inicio  = pd.Timestamp(\"2023-03-07\")\n",
    "fin     = pd.Timestamp(\"2023-06-30\")\n",
    "\n",
    "for nombre, df in dfs_22_23.items():\n",
    "    if DAY_COL not in df.columns or df.empty:\n",
    "        continue\n",
    "\n",
    "    # Normalizar a fecha y construir máscara para CONSERVAR lo que queda fuera del rango\n",
    "    fechas = pd.to_datetime(df[DAY_COL], dayfirst=True, errors=\"coerce\").dt.normalize()\n",
    "\n",
    "    # Rango INCLUSIVO: elimina 31/12/2023 ... 30/06/2024\n",
    "    mask_keep = (fechas < inicio) | (fechas > fin) | fechas.isna()\n",
    "\n",
    "    dfs_22_23[nombre] = df.loc[mask_keep].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32834f7",
   "metadata": {},
   "source": [
    "#### Datos 2021-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65c5b064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resumen de hojas y columnas ---\n",
      "                         hoja  filas  columnas  \\\n",
      "0             Consolidado KPI  16049        62   \n",
      "1      Consolidado Produccion  15573        12   \n",
      "2    Totalizadores Produccion  15573        40   \n",
      "3              Consolidado EE  16054        21   \n",
      "4       Totalizadores Energia  15575        53   \n",
      "5            Consolidado Agua  16049        18   \n",
      "6          Totalizadores Agua  15575        43   \n",
      "7        Consolidado GasVapor  16049        17   \n",
      "8   Totalizadores Gas y Vapor  15575        22   \n",
      "9            Consolidado Aire  15912        14   \n",
      "10         Totalizadores Aire  15575        11   \n",
      "11          Totalizadores CO2  15575         8   \n",
      "12    Totalizadores Efluentes  15575         8   \n",
      "13       Totalizadores Glicol  15563         8   \n",
      "14            Seguimiento Dia  15596         4   \n",
      "15                   Auxiliar  15754        34   \n",
      "\n",
      "                                     nombres_columnas  \n",
      "0   DIA, HORA, EE Planta / Hl, EE Elaboracion / Hl...  \n",
      "1   DIA, HORA, Hl de Mosto, Hl Cerveza Cocina, Hl ...  \n",
      "2   DIA, HORA, HL Mosto Budweiser, HL Mosto Tecate...  \n",
      "3   DIA, HORA, Planta (Kw), Elaboracion (Kw), Bode...  \n",
      "4   DIA, HORA, KW Gral Planta, KW Trafo 4, KW Traf...  \n",
      "5   DIA, HORA, Agua Planta (Hl), Agua Elaboracion ...  \n",
      "6   DIA, HORA, Red L1 y L2, FC L1 y L2, Red Paste ...  \n",
      "7   DIA, HORA, Conversion Kg/Mj, Gas Planta (Mj), ...  \n",
      "8   DIA, HORA, M3_Tot_Gas, Tot_Vapor_Caldera 3, To...  \n",
      "9   DIA, HORA, Aire Producido (M3), Aire Planta (M...  \n",
      "10  DIA, HORA, Totalizador_Aire_L2, Totalizador_Ai...  \n",
      "11  DIA, HORA, Totalizador_L2_Barriles, Totalizado...  \n",
      "12  DIA, HORA, Totalizador Bba P1, Totalizador Bba...  \n",
      "13  DIA, HORA, Tot Fermantacion_Cocina, Tot Reposo...  \n",
      "14                 DIA, HORA, Ultimo Dato del Dia, Id  \n",
      "15  DIA, HORA,  ,  .1,  .2,  .3,  .4,  .5,  .6,  ....  \n"
     ]
    }
   ],
   "source": [
    "# 1) Cargar el archivo una sola vez\n",
    "xls = pd.ExcelFile('data/Totalizadores Planta de Cerveza 2021_2022.xlsx')\n",
    "\n",
    "# 2) Crear un dict con un DataFrame por hoja\n",
    "dfs_2021_2022 = {}\n",
    "resumen = []\n",
    "\n",
    "for hoja in xls.sheet_names:\n",
    "    df = pd.read_excel(xls, sheet_name=hoja)\n",
    "    dfs_2021_2022[hoja] = df\n",
    "    resumen.append({\n",
    "        \"hoja\": hoja,\n",
    "        \"filas\": len(df),\n",
    "        \"columnas\": df.shape[1],\n",
    "        \"nombres_columnas\": \", \".join(map(str, df.columns.tolist()))\n",
    "    })\n",
    "\n",
    "# 3) Mostrar un resumen amigable\n",
    "resumen_df = pd.DataFrame(resumen)\n",
    "\n",
    "print(\"--- Resumen de hojas y columnas ---\")\n",
    "print(resumen_df)\n",
    "\n",
    "# Nota: Los DataFrames quedan disponibles en el dict dfs (ej: dfs[\"NombreDeLaHoja\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6cf529",
   "metadata": {},
   "source": [
    "### **Dias faltantes:**\n",
    "- 31-03-2021\n",
    "- 31-05-2021\n",
    "- 31-10-2021\n",
    "- 31-12-2021\n",
    "- desde 17-03-2022 hasta 30-06-2022\n",
    "- 31-10-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d3be73",
   "metadata": {},
   "source": [
    "### **Creacion del diccionario:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c9102a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "\n",
    "dfs_21_22 = {}\n",
    "hojas_saltadas = []\n",
    "\n",
    "for hoja, df in dfs_2021_2022.items():\n",
    "    if DAY_COL not in df.columns or HOUR_COL not in df.columns:\n",
    "        hojas_saltadas.append((hoja, \"Falta DIA u HORA\"))\n",
    "        continue\n",
    "\n",
    "    tmp = df.copy()\n",
    "    tmp[\"_dia\"]  = tmp[DAY_COL].map(_to_date)\n",
    "    tmp[\"_mins\"] = tmp[HOUR_COL].map(_to_minutes)\n",
    "\n",
    "    # Filtramos filas sin día y agregamos orden determinístico\n",
    "    tmp = tmp.dropna(subset=[\"_dia\"]).copy()\n",
    "    if tmp.empty:\n",
    "        hojas_saltadas.append((hoja, \"Sin días válidos\"))\n",
    "        continue\n",
    "\n",
    "    tmp[\"_ord\"] = np.arange(len(tmp))  # <- evita usar el índice en sort_values\n",
    "\n",
    "    # Orden por día, hora (minutos) y orden original\n",
    "    tmp = tmp.sort_values([\"_dia\", \"_mins\", \"_ord\"], kind=\"stable\")\n",
    "\n",
    "    # Última fila por día (la mayor \"_mins\"; si empata, la última por \"_ord\")\n",
    "    ultimas = tmp.groupby(\"_dia\", as_index=False, sort=True).tail(1)\n",
    "\n",
    "    # Limpieza de columnas auxiliares y orden final\n",
    "    ultimas = ultimas.drop(columns=[\"_dia\", \"_mins\", \"_ord\"]).sort_values(DAY_COL).reset_index(drop=True)\n",
    "\n",
    "    dfs_21_22[hoja] = ultimas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd0c4ad",
   "metadata": {},
   "source": [
    "### **3 filas con última hora distinta de 23:59:**\n",
    "- 2022-03-02 -> 23:00:00\n",
    "- 2022-03-16 -> 07:00:00\t\n",
    "- 2022-07-13 -> 23:00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e8d006",
   "metadata": {},
   "source": [
    "### **Interpolacioón:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c22db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "\n",
    "# Aplicarlo a TODO el diccionario (una hoja por vez)\n",
    "for nombre, df in dfs_21_22.items():\n",
    "    dfs_21_22[nombre] = completar_e_interpolar_diario(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a02f1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL = \"DIA\"\n",
    "inicio  = pd.Timestamp(\"2022-03-17\")\n",
    "fin     = pd.Timestamp(\"2022-06-30\")\n",
    "\n",
    "for nombre, df in dfs_21_22.items():\n",
    "    if DAY_COL not in df.columns or df.empty:\n",
    "        continue\n",
    "\n",
    "    # Normalizar a fecha y construir máscara para CONSERVAR lo que queda fuera del rango\n",
    "    fechas = pd.to_datetime(df[DAY_COL], dayfirst=True, errors=\"coerce\").dt.normalize()\n",
    "\n",
    "    # Rango INCLUSIVO: elimina 31/12/2023 ... 30/06/2024\n",
    "    mask_keep = (fechas < inicio) | (fechas > fin) | fechas.isna()\n",
    "\n",
    "    dfs_21_22[nombre] = df.loc[mask_keep].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3853aa18",
   "metadata": {},
   "source": [
    "## **Análisis descriptivo y versionado de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b3005",
   "metadata": {},
   "source": [
    "Podemos ver que los datos comparten muchos días, por lo que son datos duplicados. Por eso vamos a crear un solo data frame que tenga todos los datos ordenados cronológicamente una sola vez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb03fc",
   "metadata": {},
   "source": [
    "#### Checksum (no sabemos donde ponerlo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c75ac846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- Calculando Checksum de Datos Crudos ---\n",
      "Total de hojas (DataFrames) crudos encontrados: 52\n",
      "DataFrame crudo unificado tiene 708963 filas y 438 columnas.\n",
      "Ordenando datos crudos por 'HORA'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angim\\AppData\\Local\\Temp\\ipykernel_19092\\1030262672.py:33: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_crudo_total[columna_orden] = pd.to_datetime(df_crudo_total[columna_orden], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convirtiendo DataFrame ordenado a bytes...\n",
      "Calculando hash MD5...\n",
      "¡Checksum MD5 de datos crudos!: f7b8d7c5153f2dd7e0ddac7d4fe1a435\n",
      "Checksum guardado exitosamente en: data\\checksums.json\n"
     ]
    }
   ],
   "source": [
    "# --- Checksum Calculation Block ---\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "\n",
    "print(\"\\\\n--- Calculando Checksum de Datos Crudos ---\")\n",
    "\n",
    "# --- Paso 2: Reunir todos los DataFrames crudos ---\n",
    "lista_dfs_crudos = []\n",
    "if 'dfs_2023_2024' in locals():\n",
    "    lista_dfs_crudos.extend(dfs_2023_2024.values())\n",
    "if 'dfs_2022_2023' in locals():\n",
    "    lista_dfs_crudos.extend(dfs_2022_2023.values())\n",
    "if 'dfs_2021_2022' in locals():\n",
    "    lista_dfs_crudos.extend(dfs_2021_2022.values())\n",
    "\n",
    "print(f\"Total de hojas (DataFrames) crudos encontrados: {len(lista_dfs_crudos)}\")\n",
    "\n",
    "if not lista_dfs_crudos:\n",
    "    print(\"¡Advertencia! No se encontraron DataFrames crudos para calcular el checksum.\")\n",
    "else:\n",
    "    # --- Paso 3: Unificar todo ---\n",
    "    # Usamos sort=False para eficiencia, ordenaremos después explícitamente\n",
    "    df_crudo_total = pd.concat(lista_dfs_crudos, ignore_index=True, sort=False)\n",
    "    print(f\"DataFrame crudo unificado tiene {df_crudo_total.shape[0]} filas y {df_crudo_total.shape[1]} columnas.\")\n",
    "\n",
    "    # --- Paso 4: ¡Ordenar! ---\n",
    "    # Asumimos que 'HORA' es la columna de timestamp más fiable en los datos crudos\n",
    "    columna_orden = 'HORA'\n",
    "    if columna_orden in df_crudo_total.columns:\n",
    "        print(f\"Ordenando datos crudos por '{columna_orden}'...\")\n",
    "        # Aseguramos que HORA sea datetime para un orden correcto, ignorando errores\n",
    "        df_crudo_total[columna_orden] = pd.to_datetime(df_crudo_total[columna_orden], errors='coerce')\n",
    "        # Ordenamos, poniendo NaT (fechas no válidas) al final para consistencia\n",
    "        df_crudo_ordenado = df_crudo_total.sort_values(by=columna_orden, kind='stable', na_position='last').reset_index(drop=True)\n",
    "    else:\n",
    "        print(f\"¡Advertencia! No se encontró la columna '{columna_orden}' para ordenar. El checksum podría no ser reproducible.\")\n",
    "        # Como fallback MUY BÁSICO, intentamos ordenar por todas las columnas\n",
    "        # Esto es lento y menos robusto, pero mejor que nada.\n",
    "        try:\n",
    "            df_crudo_ordenado = df_crudo_total.sort_values(by=df_crudo_total.columns.tolist()).reset_index(drop=True)\n",
    "            print(\"Fallback: Ordenando por todas las columnas.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al intentar ordenar por todas las columnas: {e}. Checksum no se calculará.\")\n",
    "            df_crudo_ordenado = None # Marcamos para no continuar\n",
    "\n",
    "    if df_crudo_ordenado is not None:\n",
    "        # --- Paso 5: Convertir a bytes ---\n",
    "        print(\"Convirtiendo DataFrame ordenado a bytes...\")\n",
    "        try:\n",
    "            datos_en_bytes = df_crudo_ordenado.to_csv(index=False, encoding='utf-8').encode('utf-8')\n",
    "        except Exception as e:\n",
    "            print(f\"Error al convertir a CSV/bytes: {e}. Usando representación de string como fallback.\")\n",
    "            # Fallback muy simple si to_csv falla (raro)\n",
    "            datos_en_bytes = str(df_crudo_ordenado.to_dict(orient='records')).encode('utf-8')\n",
    "\n",
    "\n",
    "        # --- Paso 6: Calcular Hash MD5 ---\n",
    "        print(\"Calculando hash MD5...\")\n",
    "        hash_md5 = hashlib.md5(datos_en_bytes).hexdigest()\n",
    "        print(f\"¡Checksum MD5 de datos crudos!: {hash_md5}\")\n",
    "\n",
    "        # --- Paso 7: Guardar ---\n",
    "        ruta_checksum = os.path.join('data', 'checksums.json')\n",
    "        checksum_info = {\n",
    "            'datos_crudos_unificados_v2': hash_md5 # v2 para diferenciar si ya había uno\n",
    "        }\n",
    "        try:\n",
    "            with open(ruta_checksum, 'w') as f:\n",
    "                json.dump(checksum_info, f, indent=4)\n",
    "            print(f\"Checksum guardado exitosamente en: {ruta_checksum}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al guardar el checksum en {ruta_checksum}: {e}\")\n",
    "\n",
    "# --- Fin del Checksum Block ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26f1c1",
   "metadata": {},
   "source": [
    "Este df_crudo_total es temporal. Solo existe dentro de ese bloque de código con el único propósito de ser \"sellado\". No lo usamos para el resto de tu análisis (tú sigues usando tus diccionarios separados, ¡lo cual está perfecto!).\n",
    "\n",
    "El checksums.json que guardamos en data/ es ese \"sello\". Cualquiera (¡incluyéndome a mí!) puede descargar tus 3 Excels, correr ese mismo bloque de código, y si el hash que obtenemos es idéntico al que tú guardaste, tenemos 100% de certeza de que estamos trabajando con exactamente los mismos datos crudos.\n",
    "\n",
    "\n",
    "**Ficha-resumen**\n",
    "- ¿Qué es df_crudo_total ? Es un DataFrame temporal que une TODOS los datos crudos de TODOS tus archivos y hojas.\n",
    "- ¿Por qué lo creamos? Para poder generar UN ÚNICO \"sello de garantía\" (checksum) que represente el 100% de tus datos de origen. Es el \"Tesoro Completo\".\n",
    "- ¿Por qué es importante? Permite que cualquier persona (tu colega, tu profesor) verifique con un solo comando si sus archivos Excel son exactamente idénticos a los tuyos. Esto se llama Integridad de Datos y es un pilar de la Reproducibilidad (MLOps).\n",
    "- ¿Cuál es el paso más importante? df.sort_values(by='HORA') . Sin ordenar los datos, dos personas con los mismos archivos podrían obtener hashes diferentes, y el checksum no serviría para nada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ed86009",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "\n",
    "RANGOS = {\n",
    "    \"dfs_21_22\": [(\"2021-01-01\", \"2021-12-31\")],\n",
    "    \"dfs_22_23\": [(\"2022-01-01\", \"2022-12-31\")],\n",
    "    \"dfs_23_24\": [(\"2023-01-01\", \"2023-12-30\"),\n",
    "                  (\"2024-07-01\", \"2024-10-26\")],\n",
    "}\n",
    "\n",
    "HOJAS_INCLUIR = [\n",
    "    \"Consolidado KPI\", \"Consolidado Produccion\", \"Totalizadores Produccion\", \"Consolidado EE\", \"Totalizadores Energia\",\n",
    "    \"Consolidado Agua\", \"Totalizadores Agua\", \"Consolidado GasVapor\", \"Totalizadores Gas y Vapor\", \"Consolidado Aire\",\n",
    "    \"Totalizadores Aire\", \"Totalizadores Efluentes\", \"Totalizadores Glicol\", \"Totalizadores CO2\"\n",
    "]\n",
    "\n",
    "DICS = {\n",
    "    \"dfs_21_22\": dfs_21_22,\n",
    "    \"dfs_22_23\": dfs_22_23,\n",
    "    \"dfs_23_24\": dfs_23_24,\n",
    "}\n",
    "\n",
    "def slice_por_fecha(df, start, end, day_col=DAY_COL):\n",
    "    if df.empty or day_col not in df.columns:\n",
    "        return df.iloc[0:0]\n",
    "    fechas = pd.to_datetime(df[day_col], errors=\"coerce\", dayfirst=True).dt.normalize()\n",
    "    mask = fechas.between(pd.to_datetime(start), pd.to_datetime(end), inclusive=\"both\")\n",
    "    return df.loc[mask].copy()\n",
    "\n",
    "def ordenar_crono(df, day_col=DAY_COL, hour_col=HOUR_COL):\n",
    "    if df.empty:\n",
    "        return df\n",
    "    dia = pd.to_datetime(df[day_col], errors=\"coerce\", dayfirst=True)\n",
    "    if hour_col in df.columns:\n",
    "        dt = pd.to_datetime(dia.dt.date.astype(str) + \" \" + df[hour_col].astype(str),\n",
    "                            errors=\"coerce\", dayfirst=True)\n",
    "    else:\n",
    "        dt = dia\n",
    "    return (df.assign(_dt=dt)\n",
    "              .sort_values(\"_dt\", kind=\"stable\", na_position=\"last\")\n",
    "              .drop(columns=\"_dt\").reset_index(drop=True))\n",
    "\n",
    "\n",
    "partes_por_hoja = defaultdict(list)\n",
    "\n",
    "for nombre_dic, dic in DICS.items():\n",
    "    rangos = RANGOS.get(nombre_dic, [])\n",
    "    for (inicio, fin) in rangos:\n",
    "        for hoja, df in dic.items():\n",
    "            if HOJAS_INCLUIR and hoja not in HOJAS_INCLUIR:\n",
    "                continue\n",
    "            recorte = slice_por_fecha(df, inicio, fin)\n",
    "            if not recorte.empty:\n",
    "                partes_por_hoja[hoja].append(recorte)\n",
    "\n",
    "dfs_completo = {}\n",
    "for hoja, partes in partes_por_hoja.items():\n",
    "    # Unificar columnas: las faltantes quedan como NaN\n",
    "    todas_cols = list(set().union(*(p.columns for p in partes)))\n",
    "    partes_alineadas = [p.reindex(columns=todas_cols) for p in partes]\n",
    "    combinado = pd.concat(partes_alineadas, ignore_index=True, sort=False)\n",
    "\n",
    "    # Orden temporal final\n",
    "    if DAY_COL in combinado.columns:\n",
    "        combinado = ordenar_crono(combinado, DAY_COL, HOUR_COL)\n",
    "    dfs_completo[hoja] = combinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e06d86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_completo['Consolidado Produccion'] = dfs_completo['Consolidado Produccion'].drop(columns=\"Fecha/Hora\", errors=\"ignore\")\n",
    "dfs_completo['Consolidado EE'] = dfs_completo['Consolidado EE'].drop(columns=['Fecha/Hora', 'Kw de Frio'], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31b5d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATRONES_DIA = (\"dia\", \"Dia\", \"DIA\")\n",
    "\n",
    "def detectar_col_dia(df, patrones=PATRONES_DIA):\n",
    "    cols = [str(c) for c in df.columns]\n",
    "    cand = [c for c in cols if any(p in c.lower() for p in patrones)]\n",
    "    if not cand:\n",
    "        raise ValueError(\"No se encontró columna de día/fecha en un DF.\")\n",
    "    # Heurística: prioriza nombres más específicos\n",
    "    preferencia = [\"dia\", \"día\", \"Dia\", \"DIA\"]\n",
    "    cand_orden = sorted(cand, key=lambda c: next((i for i,p in enumerate(preferencia) if p in c.lower()), 99))\n",
    "    return cand_orden[0]\n",
    "\n",
    "def normalizar_dia_col(df, col_dia):\n",
    "    out = df.copy(deep=True)\n",
    "    out[col_dia] = pd.to_datetime(out[col_dia], errors=\"coerce\")\n",
    "    # Si trae hora, nos quedamos con la fecha (día civil)\n",
    "    out[col_dia] = out[col_dia].dt.normalize()\n",
    "    # Renombramos a un nombre canónico común\n",
    "    if col_dia != \"dia\":\n",
    "        out = out.rename(columns={col_dia: \"dia\"})\n",
    "    return out\n",
    "\n",
    "def deduplicar_por_dia(df):\n",
    "    # Si hay múltiples filas por día en un DF, evitamos explosiones en los merges\n",
    "    # Estrategia simple: nos quedamos con la ultima por día (ajusta si necesitas otra agregación)\n",
    "    if df.duplicated(\"dia\").any():\n",
    "        df = df.sort_values(\"dia\").drop_duplicates(\"dia\", keep=\"last\")\n",
    "    return df\n",
    "\n",
    "def mergear_por_dia(dfs_completo):\n",
    "    dfs_norm = []\n",
    "    for k, df in dfs_completo.items():\n",
    "        col = detectar_col_dia(df)\n",
    "        tmp = normalizar_dia_col(df, col)\n",
    "        tmp = deduplicar_por_dia(tmp)\n",
    "        # Evita choques de nombres: agrega sufijo con la clave del dict a las columnas no-clave\n",
    "        cols_no_clave = [c for c in tmp.columns if c != \"dia\"]\n",
    "        tmp = tmp[[\"dia\"] + cols_no_clave].add_suffix(f\"__{k}\")\n",
    "        tmp = tmp.rename(columns={f\"dia__{k}\": \"dia\"})\n",
    "        dfs_norm.append(tmp)\n",
    "\n",
    "    # Merge iterativo (outer) por 'dia'\n",
    "    from functools import reduce\n",
    "    df_unificado = reduce(lambda l, r: pd.merge(l, r, on=\"dia\", how=\"outer\"), dfs_norm)\n",
    "\n",
    "    # Orden final\n",
    "    df_unificado = df_unificado.sort_values(\"dia\").reset_index(drop=True)\n",
    "    return df_unificado\n",
    "\n",
    "df_unificado = mergear_por_dia(dfs_completo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c489f34",
   "metadata": {},
   "source": [
    "Verificación de dimensiones del dataset, tipos de variables y rangos de valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "613da312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1213 entries, 0 to 1212\n",
      "Columns: 425 entries, dia to Tot L3, L4 y Planta de CO2__Totalizadores Glicol\n",
      "dtypes: datetime64[ns](1), float64(401), object(23)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_unificado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4702a037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dia</th>\n",
       "      <th>Meta ET Servicios__Consolidado KPI</th>\n",
       "      <th>Agua Envas / Hl__Consolidado KPI</th>\n",
       "      <th>Meta Aire Bodega__Consolidado KPI</th>\n",
       "      <th>Agua Paste L3 / Hl__Consolidado KPI</th>\n",
       "      <th>Meta EE Resto Serv__Consolidado KPI</th>\n",
       "      <th>Meta EE Linea 2__Consolidado KPI</th>\n",
       "      <th>Meta Aire Cocina__Consolidado KPI</th>\n",
       "      <th>Meta Agua Planta de Agua__Consolidado KPI</th>\n",
       "      <th>EE Resto Serv / Hl__Consolidado KPI</th>\n",
       "      <th>...</th>\n",
       "      <th>Id__Totalizadores Glicol</th>\n",
       "      <th>Tot  A130/330/430__Totalizadores Glicol</th>\n",
       "      <th>Tot  Trasiego__Totalizadores Glicol</th>\n",
       "      <th>Tot L3. L4 y Planta de CO2__Totalizadores Glicol</th>\n",
       "      <th>Tot Reposo Inferior__Totalizadores Glicol</th>\n",
       "      <th>Tot Fermantacion_Cocina__Totalizadores Glicol</th>\n",
       "      <th>Tot A10/20__Totalizadores Glicol</th>\n",
       "      <th>Tot A40/240/50/60/Centec/Filtro__Totalizadores Glicol</th>\n",
       "      <th>Tot  Reposo Superior__Totalizadores Glicol</th>\n",
       "      <th>Tot L3, L4 y Planta de CO2__Totalizadores Glicol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1213</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>482.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-08-31 10:42:14.542456832</td>\n",
       "      <td>3.812812</td>\n",
       "      <td>1.209606</td>\n",
       "      <td>1.517460</td>\n",
       "      <td>0.986882</td>\n",
       "      <td>0.455238</td>\n",
       "      <td>2.630265</td>\n",
       "      <td>0.505820</td>\n",
       "      <td>14.788598</td>\n",
       "      <td>0.333766</td>\n",
       "      <td>...</td>\n",
       "      <td>26792.167651</td>\n",
       "      <td>4844.695404</td>\n",
       "      <td>1460.432296</td>\n",
       "      <td>1209.291173</td>\n",
       "      <td>5675.086397</td>\n",
       "      <td>1383.276041</td>\n",
       "      <td>2114.529681</td>\n",
       "      <td>2919.339250</td>\n",
       "      <td>135.887096</td>\n",
       "      <td>3604.845039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>3.368182</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>1.307143</td>\n",
       "      <td>-0.018261</td>\n",
       "      <td>0.392143</td>\n",
       "      <td>2.265714</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>12.857143</td>\n",
       "      <td>-707.419891</td>\n",
       "      <td>...</td>\n",
       "      <td>10024.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>170.630000</td>\n",
       "      <td>224.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-10-30 00:00:00</td>\n",
       "      <td>3.486364</td>\n",
       "      <td>0.733096</td>\n",
       "      <td>1.371429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411429</td>\n",
       "      <td>2.377143</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>14.142857</td>\n",
       "      <td>0.445170</td>\n",
       "      <td>...</td>\n",
       "      <td>15333.500000</td>\n",
       "      <td>4161.860000</td>\n",
       "      <td>587.487500</td>\n",
       "      <td>606.090000</td>\n",
       "      <td>4410.960000</td>\n",
       "      <td>600.940000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1251.420000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>468.582500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-08-29 00:00:00</td>\n",
       "      <td>3.604545</td>\n",
       "      <td>0.980745</td>\n",
       "      <td>1.457143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437143</td>\n",
       "      <td>2.525714</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>14.571429</td>\n",
       "      <td>0.608472</td>\n",
       "      <td>...</td>\n",
       "      <td>31474.000000</td>\n",
       "      <td>5067.460000</td>\n",
       "      <td>1158.680000</td>\n",
       "      <td>1017.660000</td>\n",
       "      <td>5633.530000</td>\n",
       "      <td>951.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2086.520000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>1084.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-06-28 00:00:00</td>\n",
       "      <td>4.018182</td>\n",
       "      <td>1.333608</td>\n",
       "      <td>1.660714</td>\n",
       "      <td>0.097289</td>\n",
       "      <td>0.498214</td>\n",
       "      <td>2.878571</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>15.357143</td>\n",
       "      <td>0.887435</td>\n",
       "      <td>...</td>\n",
       "      <td>36776.500000</td>\n",
       "      <td>5972.937500</td>\n",
       "      <td>1688.047500</td>\n",
       "      <td>1443.190000</td>\n",
       "      <td>6959.130000</td>\n",
       "      <td>1515.620000</td>\n",
       "      <td>4870.500000</td>\n",
       "      <td>3933.295000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>5078.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-10-26 00:00:00</td>\n",
       "      <td>4.963636</td>\n",
       "      <td>55.821429</td>\n",
       "      <td>1.862143</td>\n",
       "      <td>131.700000</td>\n",
       "      <td>0.558643</td>\n",
       "      <td>3.227714</td>\n",
       "      <td>0.620714</td>\n",
       "      <td>17.871429</td>\n",
       "      <td>202.678571</td>\n",
       "      <td>...</td>\n",
       "      <td>42008.000000</td>\n",
       "      <td>11548.220000</td>\n",
       "      <td>296218.410000</td>\n",
       "      <td>9275.440000</td>\n",
       "      <td>11066.500000</td>\n",
       "      <td>10870.690000</td>\n",
       "      <td>11548.220000</td>\n",
       "      <td>12927.960000</td>\n",
       "      <td>4054.270000</td>\n",
       "      <td>27378.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489438</td>\n",
       "      <td>1.913240</td>\n",
       "      <td>0.162919</td>\n",
       "      <td>8.839278</td>\n",
       "      <td>0.048876</td>\n",
       "      <td>0.282393</td>\n",
       "      <td>0.054306</td>\n",
       "      <td>0.976547</td>\n",
       "      <td>21.434228</td>\n",
       "      <td>...</td>\n",
       "      <td>11083.098224</td>\n",
       "      <td>2110.611838</td>\n",
       "      <td>8515.193813</td>\n",
       "      <td>1008.849217</td>\n",
       "      <td>2003.208708</td>\n",
       "      <td>1452.803698</td>\n",
       "      <td>2629.050309</td>\n",
       "      <td>2230.783666</td>\n",
       "      <td>561.474599</td>\n",
       "      <td>4977.023500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 dia  Meta ET Servicios__Consolidado KPI  \\\n",
       "count                           1213                          847.000000   \n",
       "mean   2022-08-31 10:42:14.542456832                            3.812812   \n",
       "min              1970-01-01 00:00:00                            3.368182   \n",
       "25%              2021-10-30 00:00:00                            3.486364   \n",
       "50%              2022-08-29 00:00:00                            3.604545   \n",
       "75%              2023-06-28 00:00:00                            4.018182   \n",
       "max              2024-10-26 00:00:00                            4.963636   \n",
       "std                              NaN                            0.489438   \n",
       "\n",
       "       Agua Envas / Hl__Consolidado KPI  Meta Aire Bodega__Consolidado KPI  \\\n",
       "count                       1212.000000                         847.000000   \n",
       "mean                           1.209606                           1.517460   \n",
       "min                            0.003756                           1.307143   \n",
       "25%                            0.733096                           1.371429   \n",
       "50%                            0.980745                           1.457143   \n",
       "75%                            1.333608                           1.660714   \n",
       "max                           55.821429                           1.862143   \n",
       "std                            1.913240                           0.162919   \n",
       "\n",
       "       Agua Paste L3 / Hl__Consolidado KPI  \\\n",
       "count                           847.000000   \n",
       "mean                              0.986882   \n",
       "min                              -0.018261   \n",
       "25%                               0.000000   \n",
       "50%                               0.000000   \n",
       "75%                               0.097289   \n",
       "max                             131.700000   \n",
       "std                               8.839278   \n",
       "\n",
       "       Meta EE Resto Serv__Consolidado KPI  Meta EE Linea 2__Consolidado KPI  \\\n",
       "count                           847.000000                        847.000000   \n",
       "mean                              0.455238                          2.630265   \n",
       "min                               0.392143                          2.265714   \n",
       "25%                               0.411429                          2.377143   \n",
       "50%                               0.437143                          2.525714   \n",
       "75%                               0.498214                          2.878571   \n",
       "max                               0.558643                          3.227714   \n",
       "std                               0.048876                          0.282393   \n",
       "\n",
       "       Meta Aire Cocina__Consolidado KPI  \\\n",
       "count                         847.000000   \n",
       "mean                            0.505820   \n",
       "min                             0.435714   \n",
       "25%                             0.457143   \n",
       "50%                             0.485714   \n",
       "75%                             0.553571   \n",
       "max                             0.620714   \n",
       "std                             0.054306   \n",
       "\n",
       "       Meta Agua Planta de Agua__Consolidado KPI  \\\n",
       "count                                 847.000000   \n",
       "mean                                   14.788598   \n",
       "min                                    12.857143   \n",
       "25%                                    14.142857   \n",
       "50%                                    14.571429   \n",
       "75%                                    15.357143   \n",
       "max                                    17.871429   \n",
       "std                                     0.976547   \n",
       "\n",
       "       EE Resto Serv / Hl__Consolidado KPI  ...  Id__Totalizadores Glicol  \\\n",
       "count                          1212.000000  ...                847.000000   \n",
       "mean                              0.333766  ...              26792.167651   \n",
       "min                            -707.419891  ...              10024.000000   \n",
       "25%                               0.445170  ...              15333.500000   \n",
       "50%                               0.608472  ...              31474.000000   \n",
       "75%                               0.887435  ...              36776.500000   \n",
       "max                             202.678571  ...              42008.000000   \n",
       "std                              21.434228  ...              11083.098224   \n",
       "\n",
       "       Tot  A130/330/430__Totalizadores Glicol  \\\n",
       "count                               847.000000   \n",
       "mean                               4844.695404   \n",
       "min                                   0.000000   \n",
       "25%                                4161.860000   \n",
       "50%                                5067.460000   \n",
       "75%                                5972.937500   \n",
       "max                               11548.220000   \n",
       "std                                2110.611838   \n",
       "\n",
       "       Tot  Trasiego__Totalizadores Glicol  \\\n",
       "count                          1212.000000   \n",
       "mean                           1460.432296   \n",
       "min                               0.000000   \n",
       "25%                             587.487500   \n",
       "50%                            1158.680000   \n",
       "75%                            1688.047500   \n",
       "max                          296218.410000   \n",
       "std                            8515.193813   \n",
       "\n",
       "       Tot L3. L4 y Planta de CO2__Totalizadores Glicol  \\\n",
       "count                                        365.000000   \n",
       "mean                                        1209.291173   \n",
       "min                                            0.000000   \n",
       "25%                                          606.090000   \n",
       "50%                                         1017.660000   \n",
       "75%                                         1443.190000   \n",
       "max                                         9275.440000   \n",
       "std                                         1008.849217   \n",
       "\n",
       "       Tot Reposo Inferior__Totalizadores Glicol  \\\n",
       "count                                 365.000000   \n",
       "mean                                 5675.086397   \n",
       "min                                   170.630000   \n",
       "25%                                  4410.960000   \n",
       "50%                                  5633.530000   \n",
       "75%                                  6959.130000   \n",
       "max                                 11066.500000   \n",
       "std                                  2003.208708   \n",
       "\n",
       "       Tot Fermantacion_Cocina__Totalizadores Glicol  \\\n",
       "count                                     365.000000   \n",
       "mean                                     1383.276041   \n",
       "min                                       224.910000   \n",
       "25%                                       600.940000   \n",
       "50%                                       951.280000   \n",
       "75%                                      1515.620000   \n",
       "max                                     10870.690000   \n",
       "std                                      1452.803698   \n",
       "\n",
       "       Tot A10/20__Totalizadores Glicol  \\\n",
       "count                        847.000000   \n",
       "mean                        2114.529681   \n",
       "min                            0.000000   \n",
       "25%                            0.000000   \n",
       "50%                            0.000000   \n",
       "75%                         4870.500000   \n",
       "max                        11548.220000   \n",
       "std                         2629.050309   \n",
       "\n",
       "       Tot A40/240/50/60/Centec/Filtro__Totalizadores Glicol  \\\n",
       "count                                         847.000000       \n",
       "mean                                         2919.339250       \n",
       "min                                             0.000000       \n",
       "25%                                          1251.420000       \n",
       "50%                                          2086.520000       \n",
       "75%                                          3933.295000       \n",
       "max                                         12927.960000       \n",
       "std                                          2230.783666       \n",
       "\n",
       "       Tot  Reposo Superior__Totalizadores Glicol  \\\n",
       "count                                  365.000000   \n",
       "mean                                   135.887096   \n",
       "min                                      0.000000   \n",
       "25%                                      1.400000   \n",
       "50%                                      3.450000   \n",
       "75%                                     12.600000   \n",
       "max                                   4054.270000   \n",
       "std                                    561.474599   \n",
       "\n",
       "       Tot L3, L4 y Planta de CO2__Totalizadores Glicol  \n",
       "count                                        482.000000  \n",
       "mean                                        3604.845039  \n",
       "min                                            1.312500  \n",
       "25%                                          468.582500  \n",
       "50%                                         1084.690000  \n",
       "75%                                         5078.165000  \n",
       "max                                        27378.380000  \n",
       "std                                         4977.023500  \n",
       "\n",
       "[8 rows x 402 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unificado.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c172f479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HORA__Consolidado KPI',\n",
       " 'HORA__Consolidado Produccion',\n",
       " 'DIA__Consolidado Produccion',\n",
       " 'HORA__Totalizadores Produccion',\n",
       " 'Nivel Silo Bagazo Norte (1)__Totalizadores Produccion',\n",
       " 'DIA__Totalizadores Produccion',\n",
       " 'HORA__Consolidado EE',\n",
       " 'HORA__Totalizadores Energia',\n",
       " 'KW Trafo 8__Totalizadores Energia',\n",
       " 'HORA__Consolidado Agua',\n",
       " 'HORA__Totalizadores Agua',\n",
       " 'HORA__Consolidado GasVapor',\n",
       " 'HORA__Totalizadores Gas y Vapor',\n",
       " 'HORA__Consolidado Aire',\n",
       " 'HORA__Totalizadores Aire',\n",
       " 'HORA__Totalizadores CO2',\n",
       " 'Totalizador Bba P4__Totalizadores Efluentes',\n",
       " 'HORA__Totalizadores Efluentes',\n",
       " 'Totalizador Bba P51__Totalizadores Efluentes',\n",
       " 'Totalizador Bba P2__Totalizadores Efluentes',\n",
       " 'Totalizador Bba Envasado__Totalizadores Efluentes',\n",
       " 'Totalizador Bba P1__Totalizadores Efluentes',\n",
       " 'HORA__Totalizadores Glicol']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unificado.select_dtypes(include=[\"object\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "655c8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_float = [\n",
    "    \"Nivel Silo Bagazo Norte (1)__Totalizadores Produccion\",\n",
    "    \"Totalizador Bba P51__Totalizadores Efluentes\",\n",
    "    \"Totalizador Bba P2__Totalizadores Efluentes\",\n",
    "    \"Totalizador Bba P4__Totalizadores Efluentes\",\n",
    "    \"Totalizador Bba Envasado__Totalizadores Efluentes\",\n",
    "    \"Totalizador Bba P1__Totalizadores Efluentes\",\n",
    "    \"KW Trafo 8__Totalizadores Energia\",\n",
    "]\n",
    "\n",
    "df_unificado[cols_float] = (df_unificado[cols_float].astype(str).apply(lambda s: s.str.replace(r\"\\.\", \"\", regex=True).str.replace(\",\", \".\", regex=False))\n",
    "      .apply(pd.to_numeric, errors=\"coerce\").astype(\"float64\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0169f91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Todas las HORA__ son iguales en todas las filas?: False\n",
      "Filas con diferencias: 1213\n",
      "  HORA__Consolidado KPI HORA__Consolidado Produccion  \\\n",
      "0                   NaN                     07:00:00   \n",
      "1              23:59:00                          NaN   \n",
      "2              23:59:00                          NaN   \n",
      "3              23:59:00                          NaN   \n",
      "4              23:59:00                          NaN   \n",
      "5              23:59:00                          NaN   \n",
      "6              23:59:00                          NaN   \n",
      "7              23:59:00                          NaN   \n",
      "8              23:59:00                          NaN   \n",
      "9              23:59:00                          NaN   \n",
      "\n",
      "  HORA__Totalizadores Produccion HORA__Consolidado EE  \\\n",
      "0                       07:00:00                  NaN   \n",
      "1                            NaN             23:59:00   \n",
      "2                            NaN             23:59:00   \n",
      "3                            NaN             23:59:00   \n",
      "4                            NaN             23:59:00   \n",
      "5                            NaN             23:59:00   \n",
      "6                            NaN             23:59:00   \n",
      "7                            NaN             23:59:00   \n",
      "8                            NaN             23:59:00   \n",
      "9                            NaN             23:59:00   \n",
      "\n",
      "  HORA__Totalizadores Energia HORA__Consolidado Agua HORA__Totalizadores Agua  \\\n",
      "0                         NaN                    NaN                      NaN   \n",
      "1                    23:59:00               23:59:00                 23:59:00   \n",
      "2                    23:59:00               23:59:00                 23:59:00   \n",
      "3                    23:59:00               23:59:00                 23:59:00   \n",
      "4                    23:59:00               23:59:00                 23:59:00   \n",
      "5                    23:59:00               23:59:00                 23:59:00   \n",
      "6                    23:59:00               23:59:00                 23:59:00   \n",
      "7                    23:59:00               23:59:00                 23:59:00   \n",
      "8                    23:59:00               23:59:00                 23:59:00   \n",
      "9                    23:59:00               23:59:00                 23:59:00   \n",
      "\n",
      "  HORA__Consolidado GasVapor HORA__Totalizadores Gas y Vapor  \\\n",
      "0                        NaN                             NaN   \n",
      "1                   23:59:00                        23:59:00   \n",
      "2                   23:59:00                        23:59:00   \n",
      "3                   23:59:00                        23:59:00   \n",
      "4                   23:59:00                        23:59:00   \n",
      "5                   23:59:00                        23:59:00   \n",
      "6                   23:59:00                        23:59:00   \n",
      "7                   23:59:00                        23:59:00   \n",
      "8                   23:59:00                        23:59:00   \n",
      "9                   23:59:00                        23:59:00   \n",
      "\n",
      "  HORA__Consolidado Aire HORA__Totalizadores Aire HORA__Totalizadores CO2  \\\n",
      "0                    NaN                      NaN                     NaN   \n",
      "1               23:59:00                 23:59:00                23:59:00   \n",
      "2               23:59:00                 23:59:00                23:59:00   \n",
      "3               23:59:00                 23:59:00                23:59:00   \n",
      "4               23:59:00                 23:59:00                23:59:00   \n",
      "5               23:59:00                 23:59:00                23:59:00   \n",
      "6               23:59:00                 23:59:00                23:59:00   \n",
      "7               23:59:00                 23:59:00                23:59:00   \n",
      "8               23:59:00                 23:59:00                23:59:00   \n",
      "9               23:59:00                 23:59:00                23:59:00   \n",
      "\n",
      "  HORA__Totalizadores Efluentes HORA__Totalizadores Glicol  \n",
      "0                           NaN                        NaN  \n",
      "1                      23:59:00                   23:59:00  \n",
      "2                      23:59:00                   23:59:00  \n",
      "3                      23:59:00                   23:59:00  \n",
      "4                      23:59:00                   23:59:00  \n",
      "5                      23:59:00                   23:59:00  \n",
      "6                      23:59:00                   23:59:00  \n",
      "7                      23:59:00                   23:59:00  \n",
      "8                      23:59:00                   23:59:00  \n",
      "9                      23:59:00                   23:59:00  \n"
     ]
    }
   ],
   "source": [
    "cols_hora = [\n",
    "    'HORA__Consolidado KPI',\n",
    "    'HORA__Consolidado Produccion',\n",
    "    'HORA__Totalizadores Produccion',\n",
    "    'HORA__Consolidado EE',\n",
    "    'HORA__Totalizadores Energia',\n",
    "    'HORA__Consolidado Agua',\n",
    "    'HORA__Totalizadores Agua',\n",
    "    'HORA__Consolidado GasVapor',\n",
    "    'HORA__Totalizadores Gas y Vapor',\n",
    "    'HORA__Consolidado Aire',\n",
    "    'HORA__Totalizadores Aire',\n",
    "    'HORA__Totalizadores CO2',\n",
    "    'HORA__Totalizadores Efluentes',\n",
    "    'HORA__Totalizadores Glicol',\n",
    "]\n",
    "\n",
    "# 1) Igualdad exacta columna a columna (por fila), tratando NaN como iguales\n",
    "base = df_unificado[cols_hora[0]].fillna(\"__NA__\")\n",
    "iguales_mask = df_unificado[cols_hora].fillna(\"__NA__\").eq(base, axis=0)\n",
    "\n",
    "# 2) ¿Todas las columnas son iguales en todas las filas?\n",
    "todas_iguales = bool(iguales_mask.all().all())\n",
    "print(\"¿Todas las HORA__ son iguales en todas las filas?:\", todas_iguales)\n",
    "\n",
    "# 3) Filas donde NO coinciden todas\n",
    "filas_ok = iguales_mask.all(axis=1)\n",
    "diff_rows = df_unificado.loc[~filas_ok, cols_hora]\n",
    "print(\"Filas con diferencias:\", len(diff_rows))\n",
    "\n",
    "print(diff_rows.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd8a744e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angim\\AppData\\Local\\Temp\\ipykernel_19092\\3562094624.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_unificado[\"HORA\"] = pd.to_datetime(df_unificado[\"HORA__Consolidado KPI\"], errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "# crea la columna HORA\n",
    "df_unificado[\"HORA\"] = pd.to_datetime(df_unificado[\"HORA__Consolidado KPI\"], errors=\"coerce\")\n",
    "\n",
    "# elimina todas las columnas de hora originales\n",
    "df_unificado = df_unificado.drop(columns=[c for c in cols_hora if c in df_unificado.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad49ef4",
   "metadata": {},
   "source": [
    "Identificación y cuantificación de valores faltantes, detección de valores atípicos y errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e35df54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 66__Consolidado KPI                       1213\n",
       "Unnamed: 72__Consolidado KPI                       1213\n",
       "Unnamed: 46__Consolidado KPI                       1213\n",
       "Unnamed: 124__Consolidado KPI                      1213\n",
       "Unnamed: 67__Consolidado KPI                       1213\n",
       "EE Linea 5 / Hl__Consolidado KPI                   1213\n",
       "Unnamed: 123__Consolidado KPI                      1213\n",
       "Unnamed: 22__Consolidado KPI                       1213\n",
       "Unnamed: 21__Consolidado KPI                       1213\n",
       "Hl Reserva 7__Totalizadores Produccion             1213\n",
       "Unnamed: 65__Consolidado KPI                       1213\n",
       "Unnamed: 113__Consolidado KPI                      1213\n",
       "Unnamed: 35__Consolidado KPI                       1213\n",
       " __Consolidado KPI                                 1213\n",
       "Unnamed: 14__Consolidado Produccion                1213\n",
       "Unnamed: 103__Consolidado KPI                      1213\n",
       "Unnamed: 84__Consolidado KPI                       1213\n",
       "HL Mosto Indio__Totalizadores Produccion           1212\n",
       "Id__Totalizadores Produccion                       1212\n",
       "HL Mosto Amstel Lager__Totalizadores Produccion    1212\n",
       "HL Mosto Bieckert__Totalizadores Produccion        1212\n",
       "Hl Cerveza L3__Totalizadores Produccion            1212\n",
       "HL Mosto Frost__Totalizadores Produccion           1212\n",
       "Hl Session IPA__Totalizadores Produccion           1212\n",
       "Nivel Tk Restos Lev__Totalizadores Produccion      1212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unificado.isnull().sum().sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09ebead6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas con ≥ 75.0 % ceros: 18 de 412 columnas totales\n",
      "\n",
      "VAPOR DE CALDERA 1 KG__Totalizadores Gas y Vapor           99.92%\n",
      "Tot_Vapor_Caldera 3__Totalizadores Gas y Vapor             99.92%\n",
      "Fuel Oil Tk1 (Kg)__Totalizadores Gas y Vapor               99.92%\n",
      "Fuel Oil Tk2 (Kg)__Totalizadores Gas y Vapor               99.92%\n",
      "Agua Filt FMaCist CE__Totalizadores Agua                   99.92%\n",
      "Red Barriles__Totalizadores Agua                           99.92%\n",
      "Kw llum/Serv L2__Totalizadores Energia                     99.92%\n",
      "Rep Agua Cist CE__Totalizadores Agua                       99.92%\n",
      "KW Linea 4__Totalizadores Energia                          99.92%\n",
      "Totalizador Bba Gas__Totalizadores Efluentes               99.84%\n",
      "Glicol Paste L3__Totalizadores Agua                        99.01%\n",
      "TOT GAS ENTRADA PRINCIPAL M3__Totalizadores Gas y Vapor    98.27%\n",
      "KW Atlas 3__Totalizadores Energia                          91.59%\n",
      "FC Lavadora L2__Consolidado Agua                           85.33%\n",
      "FC Lavadora L2__Totalizadores Agua                         85.33%\n",
      "Agua Helada Cocina__Totalizadores Agua                     85.24%\n",
      "KW Enfr Agua Cocina__Totalizadores Energia                 85.24%\n",
      "CAUDAL DE GAS CALDERA 1 M3__Totalizadores Gas y Vapor      78.48%\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Cuenta ceros\n",
    "zero_counts = (df_unificado.eq(0) | df_unificado.eq(\"0\")).sum(axis=0)\n",
    "zero_ratio  = ((zero_counts / len(df_unificado)) * 100).sort_values(ascending=False)\n",
    "\n",
    "umbral = 75.0\n",
    "muchos_ceros = zero_ratio[zero_ratio >= umbral]\n",
    "\n",
    "print(\"\\nColumnas con ≥\", umbral, \"% ceros:\", len(muchos_ceros), 'de', len(df_unificado.columns), \"columnas totales\")\n",
    "print()\n",
    "print(muchos_ceros.apply(lambda x: f\"{x:.2f}%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a37109b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DÍAS CON PROBLEMAS EN 'Frio (Kw)':\n",
      "          dia  mal_reset  mal_monotonia\n",
      "0  2023-04-30      False           True\n",
      "1  2023-05-20      False           True\n",
      "2  2023-06-30      False           True\n",
      "3  2023-07-03      False           True\n",
      "4  2023-09-30      False           True\n",
      "5  2023-11-30      False           True\n",
      "6  2024-07-01       True          False\n",
      "7  2024-09-30      False           True\n"
     ]
    }
   ],
   "source": [
    "# Parámetros\n",
    "# Usar los nombres de columnas tal como aparecen en los DataFrames crudos\n",
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "VAL_COL  = \"Frio (Kw)\"\n",
    "EPS = 1e-6  # tolerancia numérica\n",
    "\n",
    "def _to_minutes(h):\n",
    "    # admite \"HH:MM\" o \"HH:MM:SS\"\n",
    "    try:\n",
    "        parts = str(h).split(\":\")\n",
    "        hh, mm = int(parts[0]), int(parts[1])\n",
    "        ss = int(parts[2]) if len(parts) > 2 else 0\n",
    "        return hh*60 + mm + ss/60\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# 1) Tomamos el df\n",
    "df = dfs_2023_2024[\"Consolidado EE\"].copy()\n",
    "\n",
    "# 2) Normalizamos fecha/hora y ordenamos\n",
    "df[\"_dia\"]  = pd.to_datetime(df[DAY_COL], errors=\"coerce\", dayfirst=True).dt.date\n",
    "df[\"_mins\"] = df[HORA].map(_to_minutes) if HOUR_COL not in df.columns and \"HORA\" in df.columns else df[HOUR_COL].map(_to_minutes)\n",
    "df = df.dropna(subset=[\"_dia\",\"_mins\"]).sort_values([\"_dia\",\"_mins\"])\n",
    "\n",
    "# 3) Chequeos por día\n",
    "res = []\n",
    "for dia, g in df.groupby(\"_dia\", sort=True):\n",
    "    s = pd.to_numeric(g.get(VAL_COL, pd.Series([], dtype=\"float\")), errors=\"coerce\").fillna(0.0).values\n",
    "    if len(s) == 0:\n",
    "        continue\n",
    "    bad_reset     = not (abs(s[0]) <= EPS)              # el primer valor del día no es ~0\n",
    "    bad_monotone  = (pd.Series(s).diff().fillna(0) < -EPS).any()  # hay caídas dentro del día\n",
    "    if bad_reset or bad_monotone:\n",
    "        res.append({\"dia\": dia, \"mal_reset\": bad_reset, \"mal_monotonia\": bad_monotone})\n",
    "\n",
    "mal_df = pd.DataFrame(res).sort_values(\"dia\") if res else pd.DataFrame(columns=[\"dia\", \"mal_reset\", \"mal_monotonia\"])\n",
    "\n",
    "print(\"DÍAS CON PROBLEMAS EN 'Frio (Kw)':\")\n",
    "print(mal_df if not mal_df.empty else \"✓ Todo OK (acumulado correcto y reseteo diario).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cervecera_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
