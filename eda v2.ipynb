{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d013ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "664654a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdce0f06",
   "metadata": {},
   "source": [
    "## **Carga de datos (Fase 0)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72db2e",
   "metadata": {},
   "source": [
    "#### Datos 2023-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4563e246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resumen de hojas y columnas ---\n",
      "                         hoja  filas  columnas  \\\n",
      "0             Consolidado KPI  12010       125   \n",
      "1                       Metas     48        57   \n",
      "2      Consolidado Produccion  12011        19   \n",
      "3    Totalizadores Produccion  12009        41   \n",
      "4              Consolidado EE  12011        24   \n",
      "5       Totalizadores Energia  12009        54   \n",
      "6            Consolidado Agua  12011        24   \n",
      "7          Totalizadores Agua  12009        44   \n",
      "8        Consolidado GasVapor  12011        20   \n",
      "9   Totalizadores Gas y Vapor  12009        24   \n",
      "10           Consolidado Aire  12011        14   \n",
      "11         Totalizadores Aire  12009        12   \n",
      "12          Totalizadores CO2  12009         9   \n",
      "13    Totalizadores Efluentes  12009         9   \n",
      "14       Totalizadores Glicol  12009         8   \n",
      "15            Seguimiento Dia  12009         4   \n",
      "16                   Auxiliar  12011        38   \n",
      "17          Kw Frio  Hl Mosto  12372        15   \n",
      "\n",
      "                                     nombres_columnas  \n",
      "0   DIA, HORA, EE Planta / Hl, EE Elaboracion / Hl...  \n",
      "1   Mes / Año, Año + Mes, Agua Planta, EE Planta, ...  \n",
      "2   DIA, HORA, Hl de Mosto, Hl Cerveza Cocina, Hl ...  \n",
      "3   DIA, HORA, HL Mosto Budweiser, HL Mosto Tecate...  \n",
      "4   DIA, HORA, Planta (Kw), Elaboracion (Kw), Bode...  \n",
      "5   DIA, HORA, KW Gral Planta, KW Trafo 4, KW Traf...  \n",
      "6   DIA, HORA, Agua Planta (Hl), Agua Elaboracion ...  \n",
      "7   DIA, HORA, Red L1 y L2, FC L1 y L2, Red Paste ...  \n",
      "8   DIA, HORA, Conversion Kg/Mj, Gas Planta (Mj), ...  \n",
      "9   DIA, HORA, M3_Tot_Gas, Tot_Vapor_Caldera 3, To...  \n",
      "10  DIA, HORA, Aire Producido (M3), Aire Planta (M...  \n",
      "11  DIA, HORA, Totalizador_Aire_L2, Totalizador_Ai...  \n",
      "12  DIA, HORA, Totalizador_L2_Barriles, Totalizado...  \n",
      "13  DIA, HORA, Totalizador Bba P1, Totalizador Bba...  \n",
      "14  DIA, HORA, Tot L3, L4 y Planta de CO2, Tot A40...  \n",
      "15                 DIA, HORA, Ultimo Dato del Dia, Id  \n",
      "16  Unnamed: 0, DIA, HORA, Unnamed: 3, DIA.1, HORA...  \n",
      "17  Dia, Hora, Dia / Hora, Unnamed: 3, Hl de Mosto...  \n"
     ]
    }
   ],
   "source": [
    "# 1) Cargar el archivo una sola vez\n",
    "xls = pd.ExcelFile('data/Totalizadores Planta de Cerveza 2023_2024.xlsx')\n",
    "\n",
    "# 2) Crear un dict con un DataFrame por hoja\n",
    "dfs_2023_2024 = {}\n",
    "resumen = []\n",
    "\n",
    "for hoja in xls.sheet_names:\n",
    "    df = pd.read_excel(xls, sheet_name=hoja)\n",
    "    dfs_2023_2024[hoja] = df\n",
    "    resumen.append({\n",
    "        \"hoja\": hoja,\n",
    "        \"filas\": len(df),\n",
    "        \"columnas\": df.shape[1],\n",
    "        \"nombres_columnas\": \", \".join(map(str, df.columns.tolist()))\n",
    "    })\n",
    "\n",
    "# 3) Mostrar un resumen amigable\n",
    "resumen_df = pd.DataFrame(resumen)\n",
    "\n",
    "print(\"--- Resumen de hojas y columnas ---\")\n",
    "print(resumen_df)\n",
    "\n",
    "# Nota: Los DataFrames quedan disponibles en el dict dfs (ej: dfs[\"NombreDeLaHoja\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75e41c6",
   "metadata": {},
   "source": [
    "### **Los dias faltantes son:**\n",
    "- 31-3-2023\n",
    "- 31-5-2023\n",
    "- 31-10-2023\n",
    "- desde 31-12-2023 hasta 30-6-24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab38d8",
   "metadata": {},
   "source": [
    "### **Creacion del Diccionario**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e896ffe4",
   "metadata": {},
   "source": [
    "Una vez cargada toda la hoja de datos del 2023/2024 en un diccionario, visto los días faltantes y los días en los que no se cargó la última hora (23:59), vamos a crear un diccionario con todos los df con las filas que tengan la última hora de cada día ordenado por orden cronológico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fea5708",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "\n",
    "def _to_date(x):\n",
    "    try:\n",
    "        return pd.to_datetime(x, errors=\"coerce\").date()\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def _to_minutes(x):\n",
    "    if pd.isna(x):\n",
    "        return -1\n",
    "    ts = pd.to_datetime(x, errors=\"coerce\")\n",
    "    if pd.notna(ts):\n",
    "        return int(ts.hour) * 60 + int(ts.minute)\n",
    "    try:\n",
    "        h = int(float(str(x).replace(\",\", \".\")))\n",
    "        if 0 <= h <= 23:\n",
    "            return h * 60\n",
    "    except Exception:\n",
    "        pass\n",
    "    return -1\n",
    "\n",
    "dfs_23_24 = {}\n",
    "hojas_saltadas = []\n",
    "\n",
    "for hoja, df in dfs_2023_2024.items():\n",
    "    if DAY_COL not in df.columns or HOUR_COL not in df.columns:\n",
    "        hojas_saltadas.append((hoja, \"Falta DIA u HORA\"))\n",
    "        continue\n",
    "\n",
    "    tmp = df.copy()\n",
    "    tmp[\"_dia\"]  = tmp[DAY_COL].map(_to_date)\n",
    "    tmp[\"_mins\"] = tmp[HOUR_COL].map(_to_minutes)\n",
    "\n",
    "    # Filtramos filas sin día y agregamos orden determinístico\n",
    "    tmp = tmp.dropna(subset=[\"_dia\"]).copy()\n",
    "    if tmp.empty:\n",
    "        hojas_saltadas.append((hoja, \"Sin días válidos\"))\n",
    "        continue\n",
    "\n",
    "    tmp[\"_ord\"] = np.arange(len(tmp))  # <- evita usar el índice en sort_values\n",
    "\n",
    "    # Orden por día, hora (minutos) y orden original\n",
    "    tmp = tmp.sort_values([\"_dia\", \"_mins\", \"_ord\"], kind=\"stable\")\n",
    "\n",
    "    # Última fila por día (la mayor \"_mins\"; si empata, la última por \"_ord\")\n",
    "    ultimas = tmp.groupby(\"_dia\", as_index=False, sort=True).tail(1)\n",
    "\n",
    "    # Limpieza de columnas auxiliares y orden final\n",
    "    ultimas = ultimas.drop(columns=[\"_dia\", \"_mins\", \"_ord\"]).sort_values(DAY_COL).reset_index(drop=True)\n",
    "\n",
    "    dfs_23_24[hoja] = ultimas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4f08d",
   "metadata": {},
   "source": [
    "### **4 filas con última hora distinta de 23:59**\n",
    "- 2023-02-28 -> 23:00:00    \n",
    "- 2023-04-13 -> 19:00:00    \n",
    "- 2023-04-19 -> 16:00:00    \n",
    "- 2024-10-26 -> 07:00:00    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66394821",
   "metadata": {},
   "source": [
    "### **Interpolación**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f77ba0",
   "metadata": {},
   "source": [
    "Vamos a interpolar los 5 días faltantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ef53f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "\n",
    "def completar_e_interpolar_diario(df, day_col=DAY_COL, hour_col=HOUR_COL, hora_por_defecto=\"23:59:00\"):\n",
    "    g = df.copy()\n",
    "\n",
    "    # --- fecha como datetime (normalizada al día) ---\n",
    "    g[\"_fecha\"] = pd.to_datetime(g[day_col], errors=\"coerce\", dayfirst=True).dt.normalize()\n",
    "    g = g.dropna(subset=[\"_fecha\"]).sort_values(\"_fecha\").drop_duplicates(\"_fecha\", keep=\"last\")\n",
    "\n",
    "    # --- índice continuo día a día (agrega los días faltantes) ---\n",
    "    idx_full = pd.date_range(g[\"_fecha\"].min(), g[\"_fecha\"].max(), freq=\"D\")\n",
    "    g = g.set_index(\"_fecha\").reindex(idx_full)\n",
    "\n",
    "    # --- reconstruir columnas de fecha/hora ---\n",
    "    g[day_col] = g.index.date\n",
    "    if hour_col in g.columns:\n",
    "        g[hour_col] = g[hour_col].fillna(hora_por_defecto)\n",
    "    else:\n",
    "        g[hour_col] = hora_por_defecto\n",
    "\n",
    "    # --- interpolación SOLO en columnas numéricas ---\n",
    "    num_cols = g.select_dtypes(include=\"number\").columns\n",
    "    if len(num_cols):\n",
    "        # usa el índice temporal para interpolar; luego rellena bordes\n",
    "        g[num_cols] = g[num_cols].interpolate(method=\"time\").ffill().bfill()\n",
    "\n",
    "    return g.reset_index(drop=True)\n",
    "\n",
    "# Aplicarlo a TODO el diccionario (una hoja por vez)\n",
    "for nombre, df in dfs_23_24.items():\n",
    "    dfs_23_24[nombre] = completar_e_interpolar_diario(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ad36346",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL = \"DIA\"\n",
    "inicio  = pd.Timestamp(\"2023-12-31\")\n",
    "fin     = pd.Timestamp(\"2024-06-30\")\n",
    "\n",
    "for nombre, df in dfs_23_24.items():\n",
    "    if DAY_COL not in df.columns or df.empty:\n",
    "        continue\n",
    "\n",
    "    # Normalizar a fecha y construir máscara para CONSERVAR lo que queda fuera del rango\n",
    "    fechas = pd.to_datetime(df[DAY_COL], dayfirst=True, errors=\"coerce\").dt.normalize()\n",
    "\n",
    "    # Rango INCLUSIVO: elimina 31/12/2023 ... 30/06/2024\n",
    "    mask_keep = (fechas < inicio) | (fechas > fin) | fechas.isna()\n",
    "\n",
    "    dfs_23_24[nombre] = df.loc[mask_keep].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492cb80d",
   "metadata": {},
   "source": [
    "#### Datos 2022-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df6bfb",
   "metadata": {},
   "source": [
    "Repetimos todo el proceso para los datos del 2022-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7dc1cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resumen de hojas y columnas ---\n",
      "                         hoja  filas  columnas  \\\n",
      "0             Consolidado KPI  15317       123   \n",
      "1                       Metas     36        57   \n",
      "2      Consolidado Produccion  15450        14   \n",
      "3    Totalizadores Produccion  15316        40   \n",
      "4              Consolidado EE  15450        24   \n",
      "5       Totalizadores Energia  15316        59   \n",
      "6            Consolidado Agua  15451        24   \n",
      "7          Totalizadores Agua  15316        43   \n",
      "8        Consolidado GasVapor  15460        20   \n",
      "9   Totalizadores Gas y Vapor  15316        23   \n",
      "10           Consolidado Aire  15649        14   \n",
      "11         Totalizadores Aire  15316        11   \n",
      "12          Totalizadores CO2  15317         8   \n",
      "13    Totalizadores Efluentes  15316         8   \n",
      "14       Totalizadores Glicol  15316         7   \n",
      "15            Seguimiento Dia  15316         5   \n",
      "16                   Auxiliar  15754        34   \n",
      "17          Kw Frio  Hl Mosto   6352        15   \n",
      "\n",
      "                                     nombres_columnas  \n",
      "0   DIA, HORA, EE Planta / Hl, EE Elaboracion / Hl...  \n",
      "1   Mes / Año, Año + Mes, Agua Planta, EE Planta, ...  \n",
      "2   DIA, HORA, Hl de Mosto, Hl Cerveza Cocina, Hl ...  \n",
      "3   DIA, HORA, HL Mosto Budweiser, HL Mosto Tecate...  \n",
      "4   DIA, HORA, Planta (Kw), Elaboracion (Kw), Bode...  \n",
      "5   DIA, HORA, KW Gral Planta, KW Trafo 4, KW Traf...  \n",
      "6   DIA, HORA, Agua Planta (Hl), Agua Elaboracion ...  \n",
      "7   DIA, HORA, Red L1 y L2, FC L1 y L2, Red Paste ...  \n",
      "8   DIA, HORA, Conversion Kg/Mj, Gas Planta (Mj), ...  \n",
      "9   DIA, HORA, M3_Tot_Gas, Tot_Vapor_Caldera 3, To...  \n",
      "10  DIA, HORA, Aire Producido (M3), Aire Planta (M...  \n",
      "11  DIA, HORA, Totalizador_Aire_L2, Totalizador_Ai...  \n",
      "12  DIA, HORA, Totalizador_L2_Barriles, Totalizado...  \n",
      "13  DIA, HORA, Totalizador Bba P1, Totalizador Bba...  \n",
      "14  DIA, HORA, Tot L3. L4 y Planta de CO2, Tot A40...  \n",
      "15  DIA, HORA, Ultimo Dato del Dia, Unnamed: 3, Un...  \n",
      "16  DIA, HORA,  ,  .1,  .2,  .3,  .4,  .5,  .6,  ....  \n",
      "17  Dia, Hora, Dia / Hora, Unnamed: 3, Hl de Mosto...  \n"
     ]
    }
   ],
   "source": [
    "# 1) Cargar el archivo una sola vez\n",
    "xls = pd.ExcelFile('data/Totalizadores Planta de Cerveza - 2022_2023.xlsx')\n",
    "\n",
    "# 2) Crear un dict con un DataFrame por hoja\n",
    "dfs_2022_2023 = {}\n",
    "resumen = []\n",
    "\n",
    "for hoja in xls.sheet_names:\n",
    "    df = pd.read_excel(xls, sheet_name=hoja)\n",
    "    dfs_2022_2023[hoja] = df\n",
    "    resumen.append({\n",
    "        \"hoja\": hoja,\n",
    "        \"filas\": len(df),\n",
    "        \"columnas\": df.shape[1],\n",
    "        \"nombres_columnas\": \", \".join(map(str, df.columns.tolist()))\n",
    "    })\n",
    "\n",
    "# 3) Mostrar un resumen amigable\n",
    "resumen_df = pd.DataFrame(resumen)\n",
    "\n",
    "print(\"--- Resumen de hojas y columnas ---\")\n",
    "print(resumen_df)\n",
    "\n",
    "# Nota: Los DataFrames quedan disponibles en el dict dfs (ej: dfs[\"NombreDeLaHoja\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901c1976",
   "metadata": {},
   "source": [
    "### **Los dias faltantes son:**\n",
    "- 31-3-2023\n",
    "- 31-5-2023\n",
    "- 31-10-2023\n",
    "- desde 07-03-2023 hasta 30-06-23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b307c5",
   "metadata": {},
   "source": [
    "### **Creacion del diccionario**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df854b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "\n",
    "dfs_22_23 = {}\n",
    "hojas_saltadas = []\n",
    "\n",
    "for hoja, df in dfs_2022_2023.items():\n",
    "    if DAY_COL not in df.columns or HOUR_COL not in df.columns:\n",
    "        hojas_saltadas.append((hoja, \"Falta DIA u HORA\"))\n",
    "        continue\n",
    "\n",
    "    tmp = df.copy()\n",
    "    tmp[\"_dia\"]  = tmp[DAY_COL].map(_to_date)\n",
    "    tmp[\"_mins\"] = tmp[HOUR_COL].map(_to_minutes)\n",
    "\n",
    "    # Filtramos filas sin día y agregamos orden determinístico\n",
    "    tmp = tmp.dropna(subset=[\"_dia\"]).copy()\n",
    "    if tmp.empty:\n",
    "        hojas_saltadas.append((hoja, \"Sin días válidos\"))\n",
    "        continue\n",
    "\n",
    "    tmp[\"_ord\"] = np.arange(len(tmp))  # <- evita usar el índice en sort_values\n",
    "\n",
    "    # Orden por día, hora (minutos) y orden original\n",
    "    tmp = tmp.sort_values([\"_dia\", \"_mins\", \"_ord\"], kind=\"stable\")\n",
    "\n",
    "    # Última fila por día (la mayor \"_mins\"; si empata, la última por \"_ord\")\n",
    "    ultimas = tmp.groupby(\"_dia\", as_index=False, sort=True).tail(1)\n",
    "\n",
    "    # Limpieza de columnas auxiliares y orden final\n",
    "    ultimas = ultimas.drop(columns=[\"_dia\", \"_mins\", \"_ord\"]).sort_values(DAY_COL).reset_index(drop=True)\n",
    "\n",
    "    dfs_22_23[hoja] = ultimas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230c2908",
   "metadata": {},
   "source": [
    "**4 filas con última hora distinta de 23:59**\n",
    "- 2022-03-02 -> 23:00:00    \n",
    "- 2022-07-13 -> 23:00:00    \n",
    "- 2023-02-28 -> 23:00:00    \n",
    "- 2023-03-06 -> 08:00:00    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea42918",
   "metadata": {},
   "source": [
    "### **Interpolación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c773668",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "\n",
    "# Aplicarlo a TODO el diccionario (una hoja por vez)\n",
    "for nombre, df in dfs_22_23.items():\n",
    "    dfs_22_23[nombre] = completar_e_interpolar_diario(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2399557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL = \"DIA\"\n",
    "inicio  = pd.Timestamp(\"2023-03-07\")\n",
    "fin     = pd.Timestamp(\"2023-06-30\")\n",
    "\n",
    "for nombre, df in dfs_22_23.items():\n",
    "    if DAY_COL not in df.columns or df.empty:\n",
    "        continue\n",
    "\n",
    "    # Normalizar a fecha y construir máscara para CONSERVAR lo que queda fuera del rango\n",
    "    fechas = pd.to_datetime(df[DAY_COL], dayfirst=True, errors=\"coerce\").dt.normalize()\n",
    "\n",
    "    # Rango INCLUSIVO: elimina 31/12/2023 ... 30/06/2024\n",
    "    mask_keep = (fechas < inicio) | (fechas > fin) | fechas.isna()\n",
    "\n",
    "    dfs_22_23[nombre] = df.loc[mask_keep].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32834f7",
   "metadata": {},
   "source": [
    "#### Datos 2021-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65c5b064",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m resumen \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hoja \u001b[38;5;129;01min\u001b[39;00m xls\u001b[38;5;241m.\u001b[39msheet_names:\n\u001b[1;32m----> 9\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhoja\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     dfs_2021_2022[hoja] \u001b[38;5;241m=\u001b[39m df\n\u001b[0;32m     11\u001b[0m     resumen\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhoja\u001b[39m\u001b[38;5;124m\"\u001b[39m: hoja,\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilas\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mlen\u001b[39m(df),\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumnas\u001b[39m\u001b[38;5;124m\"\u001b[39m: df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnombres_columnas\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()))\n\u001b[0;32m     16\u001b[0m     })\n",
      "File \u001b[1;32mc:\\Users\\angim\\miniconda3\\envs\\cervecera_env\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:508\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 508\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32mc:\\Users\\angim\\miniconda3\\envs\\cervecera_env\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1616\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m   1576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\n\u001b[0;32m   1577\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1578\u001b[0m     sheet_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1596\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m \u001b[38;5;124;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1614\u001b[0m \u001b[38;5;124;03m    >>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1621\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\angim\\miniconda3\\envs\\cervecera_env\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:778\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m    775\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sheet_by_index(asheetname)\n\u001b[0;32m    777\u001b[0m file_rows_needed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_rows(header, index_col, skiprows, nrows)\n\u001b[1;32m--> 778\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sheet_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msheet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_rows_needed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sheet, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# pyxlsb opens two TemporaryFiles\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     sheet\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\angim\\miniconda3\\envs\\cervecera_env\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:615\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_data\u001b[1;34m(self, sheet, file_rows_needed)\u001b[0m\n\u001b[0;32m    613\u001b[0m data: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    614\u001b[0m last_row_with_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 615\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_number, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sheet\u001b[38;5;241m.\u001b[39mrows):\n\u001b[0;32m    616\u001b[0m     converted_row \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_cell(cell) \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m row]\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m converted_row \u001b[38;5;129;01mand\u001b[39;00m converted_row[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    618\u001b[0m         \u001b[38;5;66;03m# trim trailing empty elements\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\angim\\miniconda3\\envs\\cervecera_env\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:85\u001b[0m, in \u001b[0;36mReadOnlyWorksheet._cells_by_row\u001b[1;34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_source() \u001b[38;5;28;01mas\u001b[39;00m src:\n\u001b[0;32m     78\u001b[0m     parser \u001b[38;5;241m=\u001b[39m WorkSheetParser(src,\n\u001b[0;32m     79\u001b[0m                              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shared_strings,\n\u001b[0;32m     80\u001b[0m                              data_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mdata_only,\n\u001b[0;32m     81\u001b[0m                              epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mepoch,\n\u001b[0;32m     82\u001b[0m                              date_formats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39m_date_formats,\n\u001b[0;32m     83\u001b[0m                              timedelta_formats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39m_timedelta_formats)\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mparse():\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m max_row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m idx \u001b[38;5;241m>\u001b[39m max_row:\n\u001b[0;32m     87\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\angim\\miniconda3\\envs\\cervecera_env\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:156\u001b[0m, in \u001b[0;36mWorkSheetParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m properties \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    138\u001b[0m     PRINT_TAG: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprint_options\u001b[39m\u001b[38;5;124m'\u001b[39m, PrintOptions),\n\u001b[0;32m    139\u001b[0m     MARGINS_TAG: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_margins\u001b[39m\u001b[38;5;124m'\u001b[39m, PageMargins),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    151\u001b[0m \n\u001b[0;32m    152\u001b[0m }\n\u001b[0;32m    154\u001b[0m it \u001b[38;5;241m=\u001b[39m iterparse(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource) \u001b[38;5;66;03m# add a finaliser to close the source when this becomes possible\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, element \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    157\u001b[0m     tag_name \u001b[38;5;241m=\u001b[39m element\u001b[38;5;241m.\u001b[39mtag\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tag_name \u001b[38;5;129;01min\u001b[39;00m dispatcher:\n",
      "File \u001b[1;32mc:\\Users\\angim\\miniconda3\\envs\\cervecera_env\\Lib\\xml\\etree\\ElementTree.py:1238\u001b[0m, in \u001b[0;36miterparse.<locals>.iterator\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m pullparser\u001b[38;5;241m.\u001b[39mread_events()\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;66;03m# load event buffer\u001b[39;00m\n\u001b[1;32m-> 1238\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\angim\\miniconda3\\envs\\cervecera_env\\Lib\\zipfile\\__init__.py:992\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[1;32m--> 992\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m    994\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Users\\angim\\miniconda3\\envs\\cervecera_env\\Lib\\zipfile\\__init__.py:1068\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_type \u001b[38;5;241m==\u001b[39m ZIP_DEFLATED:\n\u001b[0;32m   1067\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMIN_READ_SIZE)\n\u001b[1;32m-> 1068\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39meof \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m                  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m                  \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1) Cargar el archivo una sola vez\n",
    "xls = pd.ExcelFile('data/Totalizadores Planta de Cerveza 2021_2022.xlsx')\n",
    "\n",
    "# 2) Crear un dict con un DataFrame por hoja\n",
    "dfs_2021_2022 = {}\n",
    "resumen = []\n",
    "\n",
    "for hoja in xls.sheet_names:\n",
    "    df = pd.read_excel(xls, sheet_name=hoja)\n",
    "    dfs_2021_2022[hoja] = df\n",
    "    resumen.append({\n",
    "        \"hoja\": hoja,\n",
    "        \"filas\": len(df),\n",
    "        \"columnas\": df.shape[1],\n",
    "        \"nombres_columnas\": \", \".join(map(str, df.columns.tolist()))\n",
    "    })\n",
    "\n",
    "# 3) Mostrar un resumen amigable\n",
    "resumen_df = pd.DataFrame(resumen)\n",
    "\n",
    "print(\"--- Resumen de hojas y columnas ---\")\n",
    "print(resumen_df)\n",
    "\n",
    "# Nota: Los DataFrames quedan disponibles en el dict dfs (ej: dfs[\"NombreDeLaHoja\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6cf529",
   "metadata": {},
   "source": [
    "### **Dias faltantes:**\n",
    "- 31-03-2021\n",
    "- 31-05-2021\n",
    "- 31-10-2021\n",
    "- 31-12-2021\n",
    "- desde 17-03-2022 hasta 30-06-2022\n",
    "- 31-10-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d3be73",
   "metadata": {},
   "source": [
    "### **Creacion del diccionario:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9102a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "\n",
    "dfs_21_22 = {}\n",
    "hojas_saltadas = []\n",
    "\n",
    "for hoja, df in dfs_2021_2022.items():\n",
    "    if DAY_COL not in df.columns or HOUR_COL not in df.columns:\n",
    "        hojas_saltadas.append((hoja, \"Falta DIA u HORA\"))\n",
    "        continue\n",
    "\n",
    "    tmp = df.copy()\n",
    "    tmp[\"_dia\"]  = tmp[DAY_COL].map(_to_date)\n",
    "    tmp[\"_mins\"] = tmp[HOUR_COL].map(_to_minutes)\n",
    "\n",
    "    # Filtramos filas sin día y agregamos orden determinístico\n",
    "    tmp = tmp.dropna(subset=[\"_dia\"]).copy()\n",
    "    if tmp.empty:\n",
    "        hojas_saltadas.append((hoja, \"Sin días válidos\"))\n",
    "        continue\n",
    "\n",
    "    tmp[\"_ord\"] = np.arange(len(tmp))  # <- evita usar el índice en sort_values\n",
    "\n",
    "    # Orden por día, hora (minutos) y orden original\n",
    "    tmp = tmp.sort_values([\"_dia\", \"_mins\", \"_ord\"], kind=\"stable\")\n",
    "\n",
    "    # Última fila por día (la mayor \"_mins\"; si empata, la última por \"_ord\")\n",
    "    ultimas = tmp.groupby(\"_dia\", as_index=False, sort=True).tail(1)\n",
    "\n",
    "    # Limpieza de columnas auxiliares y orden final\n",
    "    ultimas = ultimas.drop(columns=[\"_dia\", \"_mins\", \"_ord\"]).sort_values(DAY_COL).reset_index(drop=True)\n",
    "\n",
    "    dfs_21_22[hoja] = ultimas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd0c4ad",
   "metadata": {},
   "source": [
    "### **3 filas con última hora distinta de 23:59:**\n",
    "- 2022-03-02 -> 23:00:00\n",
    "- 2022-03-16 -> 07:00:00\t\n",
    "- 2022-07-13 -> 23:00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e8d006",
   "metadata": {},
   "source": [
    "### **Interpolacioón:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c22db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "\n",
    "# Aplicarlo a TODO el diccionario (una hoja por vez)\n",
    "for nombre, df in dfs_21_22.items():\n",
    "    dfs_21_22[nombre] = completar_e_interpolar_diario(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02f1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL = \"DIA\"\n",
    "inicio  = pd.Timestamp(\"2022-03-17\")\n",
    "fin     = pd.Timestamp(\"2022-06-30\")\n",
    "\n",
    "for nombre, df in dfs_21_22.items():\n",
    "    if DAY_COL not in df.columns or df.empty:\n",
    "        continue\n",
    "\n",
    "    # Normalizar a fecha y construir máscara para CONSERVAR lo que queda fuera del rango\n",
    "    fechas = pd.to_datetime(df[DAY_COL], dayfirst=True, errors=\"coerce\").dt.normalize()\n",
    "\n",
    "    # Rango INCLUSIVO: elimina 31/12/2023 ... 30/06/2024\n",
    "    mask_keep = (fechas < inicio) | (fechas > fin) | fechas.isna()\n",
    "\n",
    "    dfs_21_22[nombre] = df.loc[mask_keep].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3853aa18",
   "metadata": {},
   "source": [
    "## **Análisis descriptivo y versionado de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b3005",
   "metadata": {},
   "source": [
    "Podemos ver que los datos comparten muchos días, por lo que son datos duplicados. Por eso vamos a crear un solo data frame que tenga todos los datos ordenados cronológicamente una sola vez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb03fc",
   "metadata": {},
   "source": [
    "#### Checksum (no sabemos donde ponerlo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26f1c1",
   "metadata": {},
   "source": [
    "Este df_crudo_total es temporal. Solo existe dentro de ese bloque de código con el único propósito de ser \"sellado\". No lo usamos para el resto de tu análisis (tú sigues usando tus diccionarios separados, ¡lo cual está perfecto!).\n",
    "\n",
    "El checksums.json que guardamos en data/ es ese \"sello\". Cualquiera (¡incluyéndome a mí!) puede descargar tus 3 Excels, correr ese mismo bloque de código, y si el hash que obtenemos es idéntico al que tú guardaste, tenemos 100% de certeza de que estamos trabajando con exactamente los mismos datos crudos.\n",
    "\n",
    "\n",
    "**Ficha-resumen**\n",
    "- ¿Qué es df_crudo_total ? Es un DataFrame temporal que une TODOS los datos crudos de TODOS tus archivos y hojas.\n",
    "- ¿Por qué lo creamos? Para poder generar UN ÚNICO \"sello de garantía\" (checksum) que represente el 100% de tus datos de origen. Es el \"Tesoro Completo\".\n",
    "- ¿Por qué es importante? Permite que cualquier persona (tu colega, tu profesor) verifique con un solo comando si sus archivos Excel son exactamente idénticos a los tuyos. Esto se llama Integridad de Datos y es un pilar de la Reproducibilidad (MLOps).\n",
    "- ¿Cuál es el paso más importante? df.sort_values(by='HORA') . Sin ordenar los datos, dos personas con los mismos archivos podrían obtener hashes diferentes, y el checksum no serviría para nada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed86009",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "\n",
    "RANGOS = {\n",
    "    \"dfs_21_22\": [(\"2021-01-01\", \"2021-12-31\")],\n",
    "    \"dfs_22_23\": [(\"2022-01-01\", \"2022-12-31\")],\n",
    "    \"dfs_23_24\": [(\"2023-01-01\", \"2023-12-30\"),\n",
    "                  (\"2024-07-01\", \"2024-10-26\")],\n",
    "}\n",
    "\n",
    "HOJAS_INCLUIR = [\n",
    "    \"Consolidado KPI\", \"Consolidado Produccion\", \"Totalizadores Produccion\", \"Consolidado EE\", \"Totalizadores Energia\",\n",
    "    \"Consolidado Agua\", \"Totalizadores Agua\", \"Consolidado GasVapor\", \"Totalizadores Gas y Vapor\", \"Consolidado Aire\",\n",
    "    \"Totalizadores Aire\", \"Totalizadores Efluentes\", \"Totalizadores Glicol\", \"Totalizadores CO2\"\n",
    "]\n",
    "\n",
    "DICS = {\n",
    "    \"dfs_21_22\": dfs_21_22,\n",
    "    \"dfs_22_23\": dfs_22_23,\n",
    "    \"dfs_23_24\": dfs_23_24,\n",
    "}\n",
    "\n",
    "def slice_por_fecha(df, start, end, day_col=DAY_COL):\n",
    "    if df.empty or day_col not in df.columns:\n",
    "        return df.iloc[0:0]\n",
    "    fechas = pd.to_datetime(df[day_col], errors=\"coerce\", dayfirst=True).dt.normalize()\n",
    "    mask = fechas.between(pd.to_datetime(start), pd.to_datetime(end), inclusive=\"both\")\n",
    "    return df.loc[mask].copy()\n",
    "\n",
    "def ordenar_crono(df, day_col=DAY_COL, hour_col=HOUR_COL):\n",
    "    if df.empty:\n",
    "        return df\n",
    "    dia = pd.to_datetime(df[day_col], errors=\"coerce\", dayfirst=True)\n",
    "    if hour_col in df.columns:\n",
    "        dt = pd.to_datetime(dia.dt.date.astype(str) + \" \" + df[hour_col].astype(str),\n",
    "                            errors=\"coerce\", dayfirst=True)\n",
    "    else:\n",
    "        dt = dia\n",
    "    return (df.assign(_dt=dt)\n",
    "              .sort_values(\"_dt\", kind=\"stable\", na_position=\"last\")\n",
    "              .drop(columns=\"_dt\").reset_index(drop=True))\n",
    "\n",
    "\n",
    "partes_por_hoja = defaultdict(list)\n",
    "\n",
    "for nombre_dic, dic in DICS.items():\n",
    "    rangos = RANGOS.get(nombre_dic, [])\n",
    "    for (inicio, fin) in rangos:\n",
    "        for hoja, df in dic.items():\n",
    "            if HOJAS_INCLUIR and hoja not in HOJAS_INCLUIR:\n",
    "                continue\n",
    "            recorte = slice_por_fecha(df, inicio, fin)\n",
    "            if not recorte.empty:\n",
    "                partes_por_hoja[hoja].append(recorte)\n",
    "\n",
    "dfs_completo = {}\n",
    "for hoja, partes in partes_por_hoja.items():\n",
    "    # Unificar columnas: las faltantes quedan como NaN\n",
    "    todas_cols = list(set().union(*(p.columns for p in partes)))\n",
    "    partes_alineadas = [p.reindex(columns=todas_cols) for p in partes]\n",
    "    combinado = pd.concat(partes_alineadas, ignore_index=True, sort=False)\n",
    "\n",
    "    # Orden temporal final\n",
    "    if DAY_COL in combinado.columns:\n",
    "        combinado = ordenar_crono(combinado, DAY_COL, HOUR_COL)\n",
    "    dfs_completo[hoja] = combinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_completo['Consolidado Produccion'] = dfs_completo['Consolidado Produccion'].drop(columns=\"Fecha/Hora\", errors=\"ignore\")\n",
    "dfs_completo['Consolidado EE'] = dfs_completo['Consolidado EE'].drop(columns=['Fecha/Hora', 'Kw de Frio'], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATRONES_DIA = (\"dia\", \"Dia\", \"DIA\")\n",
    "\n",
    "def detectar_col_dia(df, patrones=PATRONES_DIA):\n",
    "    cols = [str(c) for c in df.columns]\n",
    "    cand = [c for c in cols if any(p in c.lower() for p in patrones)]\n",
    "    if not cand:\n",
    "        raise ValueError(\"No se encontró columna de día/fecha en un DF.\")\n",
    "    # Heurística: prioriza nombres más específicos\n",
    "    preferencia = [\"dia\", \"día\", \"Dia\", \"DIA\"]\n",
    "    cand_orden = sorted(cand, key=lambda c: next((i for i,p in enumerate(preferencia) if p in c.lower()), 99))\n",
    "    return cand_orden[0]\n",
    "\n",
    "def normalizar_dia_col(df, col_dia):\n",
    "    out = df.copy(deep=True)\n",
    "    out[col_dia] = pd.to_datetime(out[col_dia], errors=\"coerce\")\n",
    "    # Si trae hora, nos quedamos con la fecha (día civil)\n",
    "    out[col_dia] = out[col_dia].dt.normalize()\n",
    "    # Renombramos a un nombre canónico común\n",
    "    if col_dia != \"dia\":\n",
    "        out = out.rename(columns={col_dia: \"dia\"})\n",
    "    return out\n",
    "\n",
    "def deduplicar_por_dia(df):\n",
    "    # Si hay múltiples filas por día en un DF, evitamos explosiones en los merges\n",
    "    # Estrategia simple: nos quedamos con la ultima por día (ajusta si necesitas otra agregación)\n",
    "    if df.duplicated(\"dia\").any():\n",
    "        df = df.sort_values(\"dia\").drop_duplicates(\"dia\", keep=\"last\")\n",
    "    return df\n",
    "\n",
    "def mergear_por_dia(dfs_completo):\n",
    "    dfs_norm = []\n",
    "    for k, df in dfs_completo.items():\n",
    "        col = detectar_col_dia(df)\n",
    "        tmp = normalizar_dia_col(df, col)\n",
    "        tmp = deduplicar_por_dia(tmp)\n",
    "        # Evita choques de nombres: agrega sufijo con la clave del dict a las columnas no-clave\n",
    "        cols_no_clave = [c for c in tmp.columns if c != \"dia\"]\n",
    "        tmp = tmp[[\"dia\"] + cols_no_clave].add_suffix(f\"__{k}\")\n",
    "        tmp = tmp.rename(columns={f\"dia__{k}\": \"dia\"})\n",
    "        dfs_norm.append(tmp)\n",
    "\n",
    "    # Merge iterativo (outer) por 'dia'\n",
    "    from functools import reduce\n",
    "    df_unificado = reduce(lambda l, r: pd.merge(l, r, on=\"dia\", how=\"outer\"), dfs_norm)\n",
    "\n",
    "    # Orden final\n",
    "    df_unificado = df_unificado.sort_values(\"dia\").reset_index(drop=True)\n",
    "    return df_unificado\n",
    "\n",
    "df_unificado = mergear_por_dia(dfs_completo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c489f34",
   "metadata": {},
   "source": [
    "Verificación de dimensiones del dataset, tipos de variables y rangos de valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613da312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1212 entries, 0 to 1211\n",
      "Columns: 425 entries, dia to Tot Reposo Inferior__Totalizadores Glicol\n",
      "dtypes: datetime64[ns](1), float64(403), object(21)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_unificado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4702a037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dia</th>\n",
       "      <th>Meta Agua Linea 4__Consolidado KPI</th>\n",
       "      <th>Meta Produccion Agua__Consolidado KPI</th>\n",
       "      <th>Agua Paste L3 / Hl__Consolidado KPI</th>\n",
       "      <th>EE Agua / Hl__Consolidado KPI</th>\n",
       "      <th>Meta Aire L4__Consolidado KPI</th>\n",
       "      <th>Aire Cocina / Hl__Consolidado KPI</th>\n",
       "      <th>Meta Agua Elab__Consolidado KPI</th>\n",
       "      <th>CO 2 Filtro / Hl__Consolidado KPI</th>\n",
       "      <th>EE Resto Serv / Hl__Consolidado KPI</th>\n",
       "      <th>...</th>\n",
       "      <th>Id__Totalizadores Glicol</th>\n",
       "      <th>Tot Fermantacion_Cocina__Totalizadores Glicol</th>\n",
       "      <th>Tot  Trasiego__Totalizadores Glicol</th>\n",
       "      <th>Tot L3, L4 y Planta de CO2__Totalizadores Glicol</th>\n",
       "      <th>Tot A40/240/50/60/Centec/Filtro__Totalizadores Glicol</th>\n",
       "      <th>Tot  A130/330/430__Totalizadores Glicol</th>\n",
       "      <th>Tot  Reposo Superior__Totalizadores Glicol</th>\n",
       "      <th>Tot A10/20__Totalizadores Glicol</th>\n",
       "      <th>Tot L3. L4 y Planta de CO2__Totalizadores Glicol</th>\n",
       "      <th>Tot Reposo Inferior__Totalizadores Glicol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1212</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>847.0</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>365.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-09-16 07:36:14.257425664</td>\n",
       "      <td>0.492953</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.986882</td>\n",
       "      <td>0.081604</td>\n",
       "      <td>0.606984</td>\n",
       "      <td>1.272859</td>\n",
       "      <td>1.804209</td>\n",
       "      <td>0.448620</td>\n",
       "      <td>0.333766</td>\n",
       "      <td>...</td>\n",
       "      <td>26792.167651</td>\n",
       "      <td>1383.276041</td>\n",
       "      <td>1460.432296</td>\n",
       "      <td>3604.845039</td>\n",
       "      <td>2919.339250</td>\n",
       "      <td>4844.695404</td>\n",
       "      <td>135.887096</td>\n",
       "      <td>2114.529681</td>\n",
       "      <td>1209.291173</td>\n",
       "      <td>5675.086397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.018261</td>\n",
       "      <td>-29.573295</td>\n",
       "      <td>0.522857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.568571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-707.419891</td>\n",
       "      <td>...</td>\n",
       "      <td>10024.000000</td>\n",
       "      <td>224.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>170.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-10-30 18:00:00</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042529</td>\n",
       "      <td>0.548571</td>\n",
       "      <td>0.733447</td>\n",
       "      <td>1.725429</td>\n",
       "      <td>0.364333</td>\n",
       "      <td>0.445170</td>\n",
       "      <td>...</td>\n",
       "      <td>15333.500000</td>\n",
       "      <td>600.940000</td>\n",
       "      <td>587.487500</td>\n",
       "      <td>468.582500</td>\n",
       "      <td>1251.420000</td>\n",
       "      <td>4161.860000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>606.090000</td>\n",
       "      <td>4410.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-08-29 12:00:00</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063969</td>\n",
       "      <td>0.582857</td>\n",
       "      <td>0.874746</td>\n",
       "      <td>1.777714</td>\n",
       "      <td>0.415926</td>\n",
       "      <td>0.608472</td>\n",
       "      <td>...</td>\n",
       "      <td>31474.000000</td>\n",
       "      <td>951.280000</td>\n",
       "      <td>1158.680000</td>\n",
       "      <td>1084.690000</td>\n",
       "      <td>2086.520000</td>\n",
       "      <td>5067.460000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1017.660000</td>\n",
       "      <td>5633.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-06-28 06:00:00</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.097289</td>\n",
       "      <td>0.090689</td>\n",
       "      <td>0.664286</td>\n",
       "      <td>1.114978</td>\n",
       "      <td>1.873571</td>\n",
       "      <td>0.481967</td>\n",
       "      <td>0.887435</td>\n",
       "      <td>...</td>\n",
       "      <td>36776.500000</td>\n",
       "      <td>1515.620000</td>\n",
       "      <td>1688.047500</td>\n",
       "      <td>5078.165000</td>\n",
       "      <td>3933.295000</td>\n",
       "      <td>5972.937500</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>4870.500000</td>\n",
       "      <td>1443.190000</td>\n",
       "      <td>6959.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-10-26 00:00:00</td>\n",
       "      <td>0.595714</td>\n",
       "      <td>85.0</td>\n",
       "      <td>131.700000</td>\n",
       "      <td>27.357143</td>\n",
       "      <td>0.744857</td>\n",
       "      <td>56.651068</td>\n",
       "      <td>2.180314</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>202.678571</td>\n",
       "      <td>...</td>\n",
       "      <td>42008.000000</td>\n",
       "      <td>10870.690000</td>\n",
       "      <td>296218.410000</td>\n",
       "      <td>27378.380000</td>\n",
       "      <td>12927.960000</td>\n",
       "      <td>11548.220000</td>\n",
       "      <td>4054.270000</td>\n",
       "      <td>11548.220000</td>\n",
       "      <td>9275.440000</td>\n",
       "      <td>11066.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.839278</td>\n",
       "      <td>1.574183</td>\n",
       "      <td>0.065168</td>\n",
       "      <td>2.540393</td>\n",
       "      <td>0.119139</td>\n",
       "      <td>0.216308</td>\n",
       "      <td>21.434228</td>\n",
       "      <td>...</td>\n",
       "      <td>11083.098224</td>\n",
       "      <td>1452.803698</td>\n",
       "      <td>8515.193813</td>\n",
       "      <td>4977.023500</td>\n",
       "      <td>2230.783666</td>\n",
       "      <td>2110.611838</td>\n",
       "      <td>561.474599</td>\n",
       "      <td>2629.050309</td>\n",
       "      <td>1008.849217</td>\n",
       "      <td>2003.208708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 404 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 dia  Meta Agua Linea 4__Consolidado KPI  \\\n",
       "count                           1212                          847.000000   \n",
       "mean   2022-09-16 07:36:14.257425664                            0.492953   \n",
       "min              2021-01-01 00:00:00                            0.428571   \n",
       "25%              2021-10-30 18:00:00                            0.471429   \n",
       "50%              2022-08-29 12:00:00                            0.485714   \n",
       "75%              2023-06-28 06:00:00                            0.511905   \n",
       "max              2024-10-26 00:00:00                            0.595714   \n",
       "std                              NaN                            0.032552   \n",
       "\n",
       "       Meta Produccion Agua__Consolidado KPI  \\\n",
       "count                                  847.0   \n",
       "mean                                    85.0   \n",
       "min                                     85.0   \n",
       "25%                                     85.0   \n",
       "50%                                     85.0   \n",
       "75%                                     85.0   \n",
       "max                                     85.0   \n",
       "std                                      0.0   \n",
       "\n",
       "       Agua Paste L3 / Hl__Consolidado KPI  EE Agua / Hl__Consolidado KPI  \\\n",
       "count                           847.000000                    1212.000000   \n",
       "mean                              0.986882                       0.081604   \n",
       "min                              -0.018261                     -29.573295   \n",
       "25%                               0.000000                       0.042529   \n",
       "50%                               0.000000                       0.063969   \n",
       "75%                               0.097289                       0.090689   \n",
       "max                             131.700000                      27.357143   \n",
       "std                               8.839278                       1.574183   \n",
       "\n",
       "       Meta Aire L4__Consolidado KPI  Aire Cocina / Hl__Consolidado KPI  \\\n",
       "count                     847.000000                        1212.000000   \n",
       "mean                        0.606984                           1.272859   \n",
       "min                         0.522857                           0.000000   \n",
       "25%                         0.548571                           0.733447   \n",
       "50%                         0.582857                           0.874746   \n",
       "75%                         0.664286                           1.114978   \n",
       "max                         0.744857                          56.651068   \n",
       "std                         0.065168                           2.540393   \n",
       "\n",
       "       Meta Agua Elab__Consolidado KPI  CO 2 Filtro / Hl__Consolidado KPI  \\\n",
       "count                       847.000000                        1212.000000   \n",
       "mean                          1.804209                           0.448620   \n",
       "min                           1.568571                           0.000000   \n",
       "25%                           1.725429                           0.364333   \n",
       "50%                           1.777714                           0.415926   \n",
       "75%                           1.873571                           0.481967   \n",
       "max                           2.180314                           6.000000   \n",
       "std                           0.119139                           0.216308   \n",
       "\n",
       "       EE Resto Serv / Hl__Consolidado KPI  ...  Id__Totalizadores Glicol  \\\n",
       "count                          1212.000000  ...                847.000000   \n",
       "mean                              0.333766  ...              26792.167651   \n",
       "min                            -707.419891  ...              10024.000000   \n",
       "25%                               0.445170  ...              15333.500000   \n",
       "50%                               0.608472  ...              31474.000000   \n",
       "75%                               0.887435  ...              36776.500000   \n",
       "max                             202.678571  ...              42008.000000   \n",
       "std                              21.434228  ...              11083.098224   \n",
       "\n",
       "       Tot Fermantacion_Cocina__Totalizadores Glicol  \\\n",
       "count                                     365.000000   \n",
       "mean                                     1383.276041   \n",
       "min                                       224.910000   \n",
       "25%                                       600.940000   \n",
       "50%                                       951.280000   \n",
       "75%                                      1515.620000   \n",
       "max                                     10870.690000   \n",
       "std                                      1452.803698   \n",
       "\n",
       "       Tot  Trasiego__Totalizadores Glicol  \\\n",
       "count                          1212.000000   \n",
       "mean                           1460.432296   \n",
       "min                               0.000000   \n",
       "25%                             587.487500   \n",
       "50%                            1158.680000   \n",
       "75%                            1688.047500   \n",
       "max                          296218.410000   \n",
       "std                            8515.193813   \n",
       "\n",
       "       Tot L3, L4 y Planta de CO2__Totalizadores Glicol  \\\n",
       "count                                        482.000000   \n",
       "mean                                        3604.845039   \n",
       "min                                            1.312500   \n",
       "25%                                          468.582500   \n",
       "50%                                         1084.690000   \n",
       "75%                                         5078.165000   \n",
       "max                                        27378.380000   \n",
       "std                                         4977.023500   \n",
       "\n",
       "       Tot A40/240/50/60/Centec/Filtro__Totalizadores Glicol  \\\n",
       "count                                         847.000000       \n",
       "mean                                         2919.339250       \n",
       "min                                             0.000000       \n",
       "25%                                          1251.420000       \n",
       "50%                                          2086.520000       \n",
       "75%                                          3933.295000       \n",
       "max                                         12927.960000       \n",
       "std                                          2230.783666       \n",
       "\n",
       "       Tot  A130/330/430__Totalizadores Glicol  \\\n",
       "count                               847.000000   \n",
       "mean                               4844.695404   \n",
       "min                                   0.000000   \n",
       "25%                                4161.860000   \n",
       "50%                                5067.460000   \n",
       "75%                                5972.937500   \n",
       "max                               11548.220000   \n",
       "std                                2110.611838   \n",
       "\n",
       "       Tot  Reposo Superior__Totalizadores Glicol  \\\n",
       "count                                  365.000000   \n",
       "mean                                   135.887096   \n",
       "min                                      0.000000   \n",
       "25%                                      1.400000   \n",
       "50%                                      3.450000   \n",
       "75%                                     12.600000   \n",
       "max                                   4054.270000   \n",
       "std                                    561.474599   \n",
       "\n",
       "       Tot A10/20__Totalizadores Glicol  \\\n",
       "count                        847.000000   \n",
       "mean                        2114.529681   \n",
       "min                            0.000000   \n",
       "25%                            0.000000   \n",
       "50%                            0.000000   \n",
       "75%                         4870.500000   \n",
       "max                        11548.220000   \n",
       "std                         2629.050309   \n",
       "\n",
       "       Tot L3. L4 y Planta de CO2__Totalizadores Glicol  \\\n",
       "count                                        365.000000   \n",
       "mean                                        1209.291173   \n",
       "min                                            0.000000   \n",
       "25%                                          606.090000   \n",
       "50%                                         1017.660000   \n",
       "75%                                         1443.190000   \n",
       "max                                         9275.440000   \n",
       "std                                         1008.849217   \n",
       "\n",
       "       Tot Reposo Inferior__Totalizadores Glicol  \n",
       "count                                 365.000000  \n",
       "mean                                 5675.086397  \n",
       "min                                   170.630000  \n",
       "25%                                  4410.960000  \n",
       "50%                                  5633.530000  \n",
       "75%                                  6959.130000  \n",
       "max                                 11066.500000  \n",
       "std                                  2003.208708  \n",
       "\n",
       "[8 rows x 404 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unificado.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c172f479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HORA__Consolidado KPI',\n",
       " 'HORA__Consolidado Produccion',\n",
       " 'HORA__Totalizadores Produccion',\n",
       " 'Nivel Silo Bagazo Norte (1)__Totalizadores Produccion',\n",
       " 'HORA__Consolidado EE',\n",
       " 'HORA__Totalizadores Energia',\n",
       " 'KW Trafo 8__Totalizadores Energia',\n",
       " 'HORA__Consolidado Agua',\n",
       " 'HORA__Totalizadores Agua',\n",
       " 'HORA__Consolidado GasVapor',\n",
       " 'HORA__Totalizadores Gas y Vapor',\n",
       " 'HORA__Consolidado Aire',\n",
       " 'HORA__Totalizadores Aire',\n",
       " 'HORA__Totalizadores CO2',\n",
       " 'Totalizador Bba P2__Totalizadores Efluentes',\n",
       " 'Totalizador Bba P1__Totalizadores Efluentes',\n",
       " 'HORA__Totalizadores Efluentes',\n",
       " 'Totalizador Bba Envasado__Totalizadores Efluentes',\n",
       " 'Totalizador Bba P51__Totalizadores Efluentes',\n",
       " 'Totalizador Bba P4__Totalizadores Efluentes',\n",
       " 'HORA__Totalizadores Glicol']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unificado.select_dtypes(include=[\"object\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_float = [\n",
    "    \"Nivel Silo Bagazo Norte (1)__Totalizadores Produccion\",\n",
    "    \"Totalizador Bba P51__Totalizadores Efluentes\",\n",
    "    \"Totalizador Bba P2__Totalizadores Efluentes\",\n",
    "    \"Totalizador Bba P4__Totalizadores Efluentes\",\n",
    "    \"Totalizador Bba Envasado__Totalizadores Efluentes\",\n",
    "    \"Totalizador Bba P1__Totalizadores Efluentes\",\n",
    "    \"KW Trafo 8__Totalizadores Energia\",\n",
    "]\n",
    "\n",
    "df_unificado[cols_float] = (df_unificado[cols_float].astype(str).apply(lambda s: s.str.replace(r\"\\.\", \"\", regex=True).str.replace(\",\", \".\", regex=False))\n",
    "      .apply(pd.to_numeric, errors=\"coerce\").astype(\"float64\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0169f91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Todas las HORA__ son iguales en todas las filas?: False\n",
      "Filas con diferencias: 2\n",
      "    HORA__Consolidado KPI HORA__Consolidado Produccion  \\\n",
      "788              23:00:00                     23:00:00   \n",
      "828              23:59:00                     23:59:00   \n",
      "\n",
      "    HORA__Totalizadores Produccion HORA__Consolidado EE  \\\n",
      "788                       23:00:00             23:00:00   \n",
      "828                       23:59:00             23:59:00   \n",
      "\n",
      "    HORA__Totalizadores Energia HORA__Consolidado Agua  \\\n",
      "788                    23:00:00               23:00:00   \n",
      "828                    23:59:00               23:59:00   \n",
      "\n",
      "    HORA__Totalizadores Agua HORA__Consolidado GasVapor  \\\n",
      "788                 23:00:00                   23:00:00   \n",
      "828                 23:59:00                   23:59:00   \n",
      "\n",
      "    HORA__Totalizadores Gas y Vapor HORA__Consolidado Aire  \\\n",
      "788                        23:00:00               23:00:00   \n",
      "828                        23:59:00               23:59:00   \n",
      "\n",
      "    HORA__Totalizadores Aire HORA__Totalizadores CO2  \\\n",
      "788                 23:00:00                23:59:00   \n",
      "828                 23:59:00                23:00:00   \n",
      "\n",
      "    HORA__Totalizadores Efluentes HORA__Totalizadores Glicol  \n",
      "788                      23:00:00                   23:00:00  \n",
      "828                      23:59:00                   23:59:00  \n"
     ]
    }
   ],
   "source": [
    "cols_hora = [\n",
    "    'HORA__Consolidado KPI',\n",
    "    'HORA__Consolidado Produccion',\n",
    "    'HORA__Totalizadores Produccion',\n",
    "    'HORA__Consolidado EE',\n",
    "    'HORA__Totalizadores Energia',\n",
    "    'HORA__Consolidado Agua',\n",
    "    'HORA__Totalizadores Agua',\n",
    "    'HORA__Consolidado GasVapor',\n",
    "    'HORA__Totalizadores Gas y Vapor',\n",
    "    'HORA__Consolidado Aire',\n",
    "    'HORA__Totalizadores Aire',\n",
    "    'HORA__Totalizadores CO2',\n",
    "    'HORA__Totalizadores Efluentes',\n",
    "    'HORA__Totalizadores Glicol',\n",
    "]\n",
    "\n",
    "# 1) Igualdad exacta columna a columna (por fila), tratando NaN como iguales\n",
    "base = df_unificado[cols_hora[0]].fillna(\"__NA__\")\n",
    "iguales_mask = df_unificado[cols_hora].fillna(\"__NA__\").eq(base, axis=0)\n",
    "\n",
    "# 2) ¿Todas las columnas son iguales en todas las filas?\n",
    "todas_iguales = bool(iguales_mask.all().all())\n",
    "print(\"¿Todas las HORA__ son iguales en todas las filas?:\", todas_iguales)\n",
    "\n",
    "# 3) Filas donde NO coinciden todas\n",
    "filas_ok = iguales_mask.all(axis=1)\n",
    "diff_rows = df_unificado.loc[~filas_ok, cols_hora]\n",
    "print(\"Filas con diferencias:\", len(diff_rows))\n",
    "\n",
    "print(diff_rows.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8a744e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angim\\AppData\\Local\\Temp\\ipykernel_17024\\3562094624.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_unificado[\"HORA\"] = pd.to_datetime(df_unificado[\"HORA__Consolidado KPI\"], errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "# crea la columna HORA\n",
    "df_unificado[\"HORA\"] = pd.to_datetime(df_unificado[\"HORA__Consolidado KPI\"], errors=\"coerce\")\n",
    "\n",
    "# elimina todas las columnas de hora originales\n",
    "df_unificado = df_unificado.drop(columns=[c for c in cols_hora if c in df_unificado.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad49ef4",
   "metadata": {},
   "source": [
    "Identificación y cuantificación de valores faltantes, detección de valores atípicos y errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e35df54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 66__Consolidado KPI                       1212\n",
       " __Consolidado KPI                                 1212\n",
       "EE Linea 5 / Hl__Consolidado KPI                   1212\n",
       "Unnamed: 124__Consolidado KPI                      1212\n",
       "Unnamed: 14__Consolidado Produccion                1212\n",
       "Unnamed: 21__Consolidado KPI                       1212\n",
       "Unnamed: 46__Consolidado KPI                       1212\n",
       "Unnamed: 22__Consolidado KPI                       1212\n",
       "Unnamed: 123__Consolidado KPI                      1212\n",
       "Unnamed: 103__Consolidado KPI                      1212\n",
       "Unnamed: 65__Consolidado KPI                       1212\n",
       "Unnamed: 113__Consolidado KPI                      1212\n",
       "Unnamed: 35__Consolidado KPI                       1212\n",
       "Unnamed: 67__Consolidado KPI                       1212\n",
       "Unnamed: 84__Consolidado KPI                       1212\n",
       "Unnamed: 72__Consolidado KPI                       1212\n",
       "Vapor _Vapor_L5 (KG)__Totalizadores Gas y Vapor     847\n",
       "Unnamed: 56__Totalizadores Energia                  847\n",
       "Tot  Reposo Superior__Totalizadores Glicol          847\n",
       "Unnamed: 54__Totalizadores Energia                  847\n",
       "Unnamed: 53__Totalizadores Energia                  847\n",
       "Unnamed: 58__Totalizadores Energia                  847\n",
       "Unnamed: 57__Totalizadores Energia                  847\n",
       "Unnamed: 55__Totalizadores Energia                  847\n",
       "Vapor _Vapor_L5 (KG)__Consolidado GasVapor          847\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unificado.isnull().sum().sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ebead6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas con ≥ 75.0 % ceros: 43 de 412 columnas totales\n",
      "\n",
      "Fuel Oil Tk2 (Kg)__Totalizadores Gas y Vapor               100.00%\n",
      "VAPOR DE CALDERA 1 KG__Totalizadores Gas y Vapor           100.00%\n",
      "Tot_Vapor_Caldera 3__Totalizadores Gas y Vapor             100.00%\n",
      "Fuel Oil Tk1 (Kg)__Totalizadores Gas y Vapor               100.00%\n",
      "KW Linea 4__Totalizadores Energia                          100.00%\n",
      "Rep Agua Cist CE__Totalizadores Agua                       100.00%\n",
      "Agua Filt FMaCist CE__Totalizadores Agua                   100.00%\n",
      "Kw llum/Serv L2__Totalizadores Energia                     100.00%\n",
      "Red Barriles__Totalizadores Agua                           100.00%\n",
      "HL Mosto Local__Totalizadores Produccion                   100.00%\n",
      "HL Mosto Budweiser__Totalizadores Produccion               100.00%\n",
      "HL Mosto Malta__Totalizadores Produccion                   100.00%\n",
      "HL Mosto Palermo__Totalizadores Produccion                 100.00%\n",
      "Hl Reserva 8__Totalizadores Produccion                     100.00%\n",
      "HL Mosto Indio__Totalizadores Produccion                   100.00%\n",
      "HL Mosto Fuerte__Totalizadores Produccion                  100.00%\n",
      "HL Mosto Bieckert__Totalizadores Produccion                100.00%\n",
      "HL Mosto Frost__Totalizadores Produccion                   100.00%\n",
      "Totalizador Bba Gas__Totalizadores Efluentes                99.92%\n",
      "Hl Mosto Blue Moon__Totalizadores Produccion                99.83%\n",
      "Hl Mosto Bieckert BAPA__Totalizadores Produccion            99.83%\n",
      "Hl Mosto Cautiva Torrontes__Totalizadores Produccion        99.75%\n",
      "Hl Mosto Bieckert Urbana__Totalizadores Produccion          99.67%\n",
      "HL Mosto Roja__Totalizadores Produccion                     99.26%\n",
      "Glicol Paste L3__Totalizadores Agua                         99.09%\n",
      "HL Mosto Amstel__Totalizadores Produccion                   99.01%\n",
      "Hl Mosto Cautiva Roja__Totalizadores Produccion             98.76%\n",
      "Hl Mosto Cautiva Blend__Totalizadores Produccion            98.68%\n",
      "TOT GAS ENTRADA PRINCIPAL M3__Totalizadores Gas y Vapor     98.35%\n",
      "HL Mosto Isenbeck__Totalizadores Produccion                 95.87%\n",
      "HL Mosto APA__Totalizadores Produccion                      95.46%\n",
      "HL Mosto Negra__Totalizadores Produccion                    95.30%\n",
      "HL Mosto Sol__Totalizadores Produccion                      94.14%\n",
      "KW Atlas 3__Totalizadores Energia                           91.67%\n",
      " HL Mosto Golden__Totalizadores Produccion                  87.46%\n",
      "HL Mosto Amstel Lager__Totalizadores Produccion             86.14%\n",
      "HL Mosto IPA__Totalizadores Produccion                      85.73%\n",
      "FC Lavadora L2__Totalizadores Agua                          85.40%\n",
      "FC Lavadora L2__Consolidado Agua                            85.40%\n",
      "KW Enfr Agua Cocina__Totalizadores Energia                  85.31%\n",
      "Agua Helada Cocina__Totalizadores Agua                      85.31%\n",
      "HL Mosto Miller__Totalizadores Produccion                   84.16%\n",
      "CAUDAL DE GAS CALDERA 1 M3__Totalizadores Gas y Vapor       78.55%\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Cuenta ceros\n",
    "zero_counts = (df_unificado.eq(0) | df_unificado.eq(\"0\")).sum(axis=0)\n",
    "zero_ratio  = ((zero_counts / len(df_unificado)) * 100).sort_values(ascending=False)\n",
    "\n",
    "umbral = 75.0\n",
    "muchos_ceros = zero_ratio[zero_ratio >= umbral]\n",
    "\n",
    "print(\"\\nColumnas con ≥\", umbral, \"% ceros:\", len(muchos_ceros), 'de', len(df_unificado.columns), \"columnas totales\")\n",
    "print()\n",
    "print(muchos_ceros.apply(lambda x: f\"{x:.2f}%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a37109b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DÍAS CON PROBLEMAS EN 'Frio (Kw)':\n",
      "          dia  mal_reset  mal_monotonia\n",
      "0  2023-04-30      False           True\n",
      "1  2023-05-20      False           True\n",
      "2  2023-06-30      False           True\n",
      "3  2023-07-03      False           True\n",
      "4  2023-09-30      False           True\n",
      "5  2023-11-30      False           True\n",
      "6  2024-07-01       True          False\n",
      "7  2024-09-30      False           True\n"
     ]
    }
   ],
   "source": [
    "# Parámetros\n",
    "# Usar los nombres de columnas tal como aparecen en los DataFrames crudos\n",
    "DAY_COL  = \"DIA\"\n",
    "HOUR_COL = \"HORA\"\n",
    "VAL_COL  = \"Frio (Kw)\"\n",
    "EPS = 1e-6  # tolerancia numérica\n",
    "\n",
    "def _to_minutes(h):\n",
    "    # admite \"HH:MM\" o \"HH:MM:SS\"\n",
    "    try:\n",
    "        parts = str(h).split(\":\")\n",
    "        hh, mm = int(parts[0]), int(parts[1])\n",
    "        ss = int(parts[2]) if len(parts) > 2 else 0\n",
    "        return hh*60 + mm + ss/60\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# 1) Tomamos el df\n",
    "df = dfs_2023_2024[\"Consolidado EE\"].copy()\n",
    "\n",
    "# 2) Normalizamos fecha/hora y ordenamos\n",
    "df[\"_dia\"]  = pd.to_datetime(df[DAY_COL], errors=\"coerce\", dayfirst=True).dt.date\n",
    "df[\"_mins\"] = df[HORA].map(_to_minutes) if HOUR_COL not in df.columns and \"HORA\" in df.columns else df[HOUR_COL].map(_to_minutes)\n",
    "df = df.dropna(subset=[\"_dia\",\"_mins\"]).sort_values([\"_dia\",\"_mins\"])\n",
    "\n",
    "# 3) Chequeos por día\n",
    "res = []\n",
    "for dia, g in df.groupby(\"_dia\", sort=True):\n",
    "    s = pd.to_numeric(g.get(VAL_COL, pd.Series([], dtype=\"float\")), errors=\"coerce\").fillna(0.0).values\n",
    "    if len(s) == 0:\n",
    "        continue\n",
    "    bad_reset     = not (abs(s[0]) <= EPS)              # el primer valor del día no es ~0\n",
    "    bad_monotone  = (pd.Series(s).diff().fillna(0) < -EPS).any()  # hay caídas dentro del día\n",
    "    if bad_reset or bad_monotone:\n",
    "        res.append({\"dia\": dia, \"mal_reset\": bad_reset, \"mal_monotonia\": bad_monotone})\n",
    "\n",
    "mal_df = pd.DataFrame(res).sort_values(\"dia\") if res else pd.DataFrame(columns=[\"dia\", \"mal_reset\", \"mal_monotonia\"])\n",
    "\n",
    "print(\"DÍAS CON PROBLEMAS EN 'Frio (Kw)':\")\n",
    "print(mal_df if not mal_df.empty else \"✓ Todo OK (acumulado correcto y reseteo diario).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import checksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d85329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checksum verificado para 'df_unificado'. El hash es el mismo. ¡No se guarda nada! 👍\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Checksum verificado: 8be83280a04cd10d9257d4a360a1a69c (ya existía bajo la clave 'df_unificado', sin cambios)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unificado = pd.read_csv(\"data/dataset_unificado.csv\")\n",
    "checksum(df_unificado, nombre_clave=\"df_unificado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cervecera_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
